{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":189706,"sourceType":"datasetVersion","datasetId":81687}],"dockerImageVersionId":30357,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"msqe with 23:291.48765266821823\nmsqe with 22:290.261147611888\nmsqe with 21:290.1394455543427\nmsqe with 20:291.39622680369905","metadata":{}},{"cell_type":"code","source":"!pip install cfbd","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:41:53.726054Z","iopub.execute_input":"2024-01-08T22:41:53.726463Z","iopub.status.idle":"2024-01-08T22:42:05.358300Z","shell.execute_reply.started":"2024-01-08T22:41:53.726427Z","shell.execute_reply":"2024-01-08T22:42:05.356967Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: cfbd in /opt/conda/lib/python3.7/site-packages (4.5.2)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from cfbd) (2.8.2)\nRequirement already satisfied: urllib3>=1.23 in /opt/conda/lib/python3.7/site-packages (from cfbd) (1.26.13)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from cfbd) (1.15.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from cfbd) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"fcs=fcs[fcs.home!='Knoxville']\nfcs=fcs[fcs.away!='Knoxville']","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.081104Z","iopub.execute_input":"2023-12-27T16:16:17.081453Z","iopub.status.idle":"2023-12-27T16:16:17.108447Z","shell.execute_reply.started":"2023-12-27T16:16:17.081419Z","shell.execute_reply":"2023-12-27T16:16:17.105862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dgz=list(set(file.home.tolist()+file.away.tolist()))+list(set(dfz.home.tolist()+dfz.away.tolist()))\ndef Convert(lst):\n    res_dct = {lst[i]: 0 for i in range(0, len(lst), 2)}\n    return res_dct\ndg=Convert(dgz)\nh=[]\nfor k in sorted(dg):\n    \n    h.append(k)\nfilez=open(\"keys.txt\",\"w\")\nfilez.write(str(h))  \nfilez.close()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.110207Z","iopub.status.idle":"2023-12-27T16:16:17.110901Z","shell.execute_reply.started":"2023-12-27T16:16:17.110679Z","shell.execute_reply":"2023-12-27T16:16:17.110703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cfbd\nimport numpy as np\n# configure API key\nconfiguration = cfbd.Configuration()\nkey=\"LX8oTIQmXarLqV7XwEcEbhkgN6ubBp0yQkA5arybroBCPul3UhonRiw0iN4eWPpK\"\nconfiguration.api_key['Authorization'] =key\nconfiguration.api_key_prefix['Authorization'] = 'Bearer'\n# instantiate a games API instance\napi_config = cfbd.ApiClient(configuration)\ngames_api = cfbd.GamesApi(cfbd.ApiClient(configuration))\ndf=dfz[dfz.season>2024]\nz=[]\ngamesz =[]\ngames=[]\nresponse = games_api.get_games(year=2020,season_type = 'both')\ngamess = [*games, *response]\nt=[]\nz=[]\ndef s(g):\n    a=dict(home=g.home_team,homeconf=g.home_conference,homep=g.home_points,away=g.away_team,awayconf=g.away_conference,awayp=g.away_points,attendance=g.attendance,neutral=g.neutral_site,season=g.season,playoff=0,date=g.start_date,week=g.week,id=g.id,season_type=g.season_type)\n    z.append(a)\nlist(map(s,gamess))\nresponse = games_api.get_games(year=2019,season_type = 'both')\ngamess = [*games, *response]\ndef s(g):\n    a=dict(home=g.home_team,homeconf=g.home_conference,homep=g.home_points,away=g.away_team,awayconf=g.away_conference,awayp=g.away_points,attendance=g.attendance,neutral=g.neutral_site,season=g.season,playoff=0,date=g.start_date,week=g.week,id=g.id,season_type=g.season_type)\n    z.append(a)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qa=from2000\nqa=qa[qa.away=='Colorado Mines']\nqa[qa.season==2016]","metadata":{"execution":{"iopub.status.busy":"2024-03-08T23:43:48.439551Z","iopub.execute_input":"2024-03-08T23:43:48.440016Z","iopub.status.idle":"2024-03-08T23:43:48.488434Z","shell.execute_reply.started":"2024-03-08T23:43:48.439976Z","shell.execute_reply":"2024-03-08T23:43:48.487242Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"                     home            away neutral  season        date  homep  \\\n31817       Colorado Mesa  Colorado Mines   False  2016.0  2016-09-17   41.0   \n31966  Western State (CO)  Colorado Mines   False  2016.0  2016-09-24   45.0   \n32569        Ferris State  Colorado Mines   False  2016.0  2016-11-26   38.0   \n\n       awayp venue1  \n31817   40.0      @  \n31966   31.0     vs  \n32569   17.0     vs  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home</th>\n      <th>away</th>\n      <th>neutral</th>\n      <th>season</th>\n      <th>date</th>\n      <th>homep</th>\n      <th>awayp</th>\n      <th>venue1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31817</th>\n      <td>Colorado Mesa</td>\n      <td>Colorado Mines</td>\n      <td>False</td>\n      <td>2016.0</td>\n      <td>2016-09-17</td>\n      <td>41.0</td>\n      <td>40.0</td>\n      <td>@</td>\n    </tr>\n    <tr>\n      <th>31966</th>\n      <td>Western State (CO)</td>\n      <td>Colorado Mines</td>\n      <td>False</td>\n      <td>2016.0</td>\n      <td>2016-09-24</td>\n      <td>45.0</td>\n      <td>31.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>32569</th>\n      <td>Ferris State</td>\n      <td>Colorado Mines</td>\n      <td>False</td>\n      <td>2016.0</td>\n      <td>2016-11-26</td>\n      <td>38.0</td>\n      <td>17.0</td>\n      <td>vs</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nimport math\nfrom datetime import date,datetime,timedelta\ncan=1\nimport os\nimport pandas as pd\n\nkey=\"LX8oTIQmXarLqV7XwEcEbhkgN6ubBp0yQkA5arybroBCPul3UhonRiw0iN4eWPpK\"\ndfz=pd.read_csv(\"https://ontheroadtovote.com/ncaab/ncaaf.csv\")\nimport cfbd\nimport numpy as np\n# configure API key\nconfiguration = cfbd.Configuration()\nconfiguration.api_key['Authorization'] =key\nconfiguration.api_key_prefix['Authorization'] = 'Bearer'\n# instantiate a games API instance\napi_config = cfbd.ApiClient(configuration)\ngames_api = cfbd.GamesApi(cfbd.ApiClient(configuration))\ndf=dfz[dfz.season>2024]\nz=[]\ngamesz =[]\ngames=[]\nresponse = games_api.get_games(year=2022,season_type = 'both')\ngamess = [*games, *response]\nt=[]\nz=[]\ndef s(g):\n    a=dict(home=g.home_team,homeconf=g.home_conference,homep=g.home_points,away=g.away_team,awayconf=g.away_conference,awayp=g.away_points,attendance=g.attendance,neutral=g.neutral_site,season=g.season,playoff=0,date=g.start_date,week=g.week,id=g.id,season_type=g.season_type)\n    z.append(a)\nlist(map(s,gamess))\nresponse = games_api.get_games(year=2023,season_type = 'both')\ngamess = [*games, *response]\ndef s(g):\n    a=dict(home=g.home_team,homeconf=g.home_conference,homep=g.home_points,away=g.away_team,awayconf=g.away_conference,awayp=g.away_points,attendance=g.attendance,neutral=g.neutral_site,season=g.season,playoff=0,date=g.start_date,week=g.week,id=g.id,season_type=g.season_type)\n    z.append(a)\nlist(map(s,gamess))\nmsqe=[]\nlh=0\nwh=0\nn=0\nfrom2000  = pd.DataFrame(z)\nfrom2000=from2000.fillna(0)\nfrom2000=from2000[(from2000.season_type=='regular')|(from2000.season_type=='postseason')]\nfrom2000=from2000\ndf=from2000\nfrom20000=from2000\nfrom2000=from2000[(from2000.homep>0)|(from2000.awayp>0)]\nfrom2000=from2000.sort_values(by='date')\nfrom decimal import Decimal\nimport decimal\ndecimal.getcontext().prec = 100\ndecimal.getcontext().Emax=1000000000\ndecimal.getcontext().Emin=-1000000000\nhfan=95\neloz={}\neloz['n']=0\neloz['wh']=0\neloz['lh']=0\nclass Elo:\n  def __init__(self,k,g=1,homefield = 100):\n    wh=0\n    lh=0\n    n=0\n    self.ratingDict   = {}  \n    self.k        = k\n    self.g        = g\n  def addPlayer(self,name,rating = 1500):\n    self.ratingDict[name] = rating\n  def gameOver(self, winner, loser, winnerHome,neutral,wins,loses,wpen,lpen):\n    if 'True' in str(neutral):\n        homef=0\n    else:\n        \n        homef=100\n    if winnerHome==True:\n      eloz['wh']+=1\n      result = self.expectResult(self.ratingDict[winner]-wpen + homef, self.ratingDict[loser]-lpen)\n    if winnerHome==0:\n      eloz['lh']+=1\n      result = self.expectResult(self.ratingDict[winner]-wpen, self.ratingDict[loser]-lpen + homef)\n    else:\n        \n        result = self.expectResult(self.ratingDict[winner]-wpen, self.ratingDict[loser]-lpen)\n\n                    \n    wins=float(wins)\n    loses=float(loses)\n    result=float(result)\n    isneutral='True'  in str(neutral) or '0' in str(neutral)\n    if wins==loses:\n        mult=(math.log(0+1))*(2.2/1*0.001+2.2)\n        shift=(self.k*mult)*(0.5 - result)  \n        self.ratingDict[winner] +=shift\n        self.ratingDict[loser]  -=shift\n    if wins!=loses:\n        win=eloLeaguez.ratingDict[winner]-wpen\n        lose=eloLeaguez.ratingDict[loser]-lpen\n        if isneutral:\n          win=(eloLeaguez.ratingDict[winner]-wpen)\n          lose=(eloLeaguez.ratingDict[loser]-lpen)\n        if winnerHome and isneutral==False:\n          win=(100+eloLeaguez.ratingDict[winner]-wpen)\n          lose=(eloLeaguez.ratingDict[loser]-lpen)\n        if winnerHome!=True and 'True' not in str(neutral) and '0' not in str(neutral):\n          lose=(100+eloLeaguez.ratingDict[loser]-lpen)\n          win=(eloLeaguez.ratingDict[winner]-wpen)\n        global zy\n        if(win>lose):\n          zy=(win-lose)\n        if(win==lose):\n          zy=(win-lose)+0.00001\n        if(win<lose):\n          zy=(win-lose)\n        mult=(math.log((abs(wins-loses))+1))*(2.2/(zy)*0.001+2.2)\n        shift=(self.k*float(mult))*(1 - result)  \n        self.ratingDict[winner] +=shift\n        self.ratingDict[loser]  -=shift\n  from math import pow\n  def expectResult(self, p1, p2):\n    p2=Decimal(p2)\n    p1=Decimal(p1)\n    exp = Decimal((p2-p1))/Decimal(400.0)\n    b=float(Decimal(Decimal(1)/((pow(Decimal(10.0),Decimal(exp)))+Decimal(1))))\n    az['h']=str(b)\n    return float(Decimal(Decimal(1)/((pow(Decimal(10.0),Decimal(exp)))+Decimal(1))))\nteamss={}\naz={}\naz['h']='hello'\ntoday = date.today()\nallTeams  = set(dfz.away.tolist()+dfz.home.tolist())\nallTeamsh  = set(dfz.home.tolist())\nglobal st\neloLeaguez= Elo(k = 20,homefield=100)\ndfz=dfz[(dfz.season_type=='postseason')|(dfz.season_type=='regular')]\nfrom2000['homeconf'].fillna(0,inplace=True)\nfrom2000['awayconf'].fillna(0,inplace=True)\n\nimport re\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom bs4 import BeautifulSoup as bs\ntds={}\n\ngz=[]\ntoday=date.today()\n\n\nimport pandas as pd\nfbsteams={}\nfor i in range(1978,2024):\n    fbsteams[i]=[]\nfor i in range(1978,2024):\n    print(i)\n    if i<2006:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I-A_football_season\"\n    else:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I_FBS_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    tablez=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    for table in tablez:\n        links=table.find_all(\"a\")\n        for a in links:\n            if 'Team' in str(table):\n                a=str(a)\n                a=a.split(\">\")\n                a=a[1]\n                a=a.split(\"<\")\n                a=a[0]\n                if 'Miami (FL)' in str(a):\n                    a=a.replace(\"Miami (FL)\",\"Miami\")\n                fbsteams[i].append(a)\narrz=[]\nfor i in range(1978,2024):\n    ts=fbsteams[i]\n    for team in ts:\n        arrz.append([team,i])\nstandingstable=pd.concat([pd.DataFrame(arrz)])\nstandingstable.columns=['Team','Season']\nimport requests\nimport json\n\nteamstor={'Miami (FL)':'Miami','North Carolina A&amp;T':\"North Carolina A&T\",\"Grambling State\":\"Grambling\",\"North Texas State\":\"North Texas\",\"Northeast Louisiana\":\"Louisiana Monroe\",\"UCF\":\"Central Florida\",\"Texas-Arlington\":\"Texas Arlington\",\"Florida A&amp;M\":\"Florida A&M\",\"SW Texas State\":\"Texas State\",\"NE Louisiana\":\"Louisiana Monroe\",\"William &amp; Mary\":\"William & Mary\",\"Southwest Texas State\":\"Texas State\",\"Troy State\":\"Troy\",\"Texas–Arlington\":\"Texas Arlington\"}\nfor team in teamstor:\n    standingstable=standingstable.replace(team,teamstor[team])\nr = requests.get('https://ontheroadtovote.com/ncaaf/fbsteams.json')\ny=r.json()\n\nfor team in y:\n    standingstable=standingstable.replace(team,y[team])\nstandingstable=standingstable[standingstable.Team!='New Mexico State']\nstandingstable=standingstable[standingstable.Team!='Tulsa']\nstandingstable=standingstable[standingstable.Team!='Wichita State']\nteams={}\nfor i in range(1978,2024):\n    teams[i]=[]\nfor row in standingstable.itertuples():\n    teams[float(row.Season)].append(str(row.Team))\nfbsteams=teams\nteams={}\nfor i in range(1978,2024):\n    teams[i]=[]\nfor i in range(1978,2024):\n    print(i)\n    if i<2006:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I-AA_football_season\"\n    else:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I_FCS_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    tablez=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    for table in tablez:\n        links=table.find_all(\"a\")\n        for a in links:\n            if 'Team' in str(table):\n                a=str(a)\n                a=a.split(\">\")\n                a=a[1]\n                a=a.split(\"<\")\n                a=a[0]\n                if 'Bethune–Cookman' in str(a):\n                    a=a.replace(\"Bethune–Cookman\",\"Bethune-Cookman\")\n                if 'Alabama A&' in str(a):\n                    a=a.replace(\"Alabama A&amp;\",\"Alabama A&M\")\n                teams[i].append(a)\narrz=[]\n\nfor i in range(1978,2024):\n    ts=teams[i]\n    for team in ts:\n        arrz.append([team,i])\nstandingstable=pd.concat([pd.DataFrame(arrz)])\nstandingstable.columns=['Team','Season']\nteamstor={'Alabama A&amp;':'Alabama A&M','North Carolina A&amp;T':\"North Carolina A&T\",\"Grambling State\":\"Grambling\",\"North Texas State\":\"North Texas\",\"Northeast Louisiana\":\"Louisiana Monroe\",\"UCF\":\"Central Florida\",\"Texas-Arlington\":\"Texas Arlington\",\"Florida A&amp;M\":\"Florida A&M\",\"SW Texas State\":\"Texas State\",\"NE Louisiana\":\"Louisiana Monroe\",\"William &amp; Mary\":\"William & Mary\",\"Southwest Texas State\":\"Texas State\",\"Troy State\":\"Troy\",\"Texas–Arlington\":\"Texas Arlington\",\"Prairie View A&amp;M\":\"Prairie View\",\"West Texas State\":\"West Texas A&M\"}\nfor team in teamstor:\n    standingstable=standingstable.replace(team,teamstor[team])\nfor team in y:\n    standingstable=standingstable.replace(team,y[team])\nstandingstable=standingstable[standingstable.Team!='New Mexico State']\nstandingstable=standingstable[standingstable.Team!='Tulsa']\nstandingstable=standingstable[standingstable.Team!='Wichita State']\nteams={}\nfor i in range(1978,2024):\n    teams[i]=[]\nfor row in standingstable.itertuples():\n    teams[float(row.Season)].append(str(row.Team))\nteamzzz=teams\nteamzzz=teams\nfrom bs4 import BeautifulSoup\nimport requests\nhtml=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/index.php\")\nsoup=BeautifulSoup(html.text)\nlinks=soup.find_all(\"a\")\narr=[]\ny=0\npts={}\narrz=[]\nns={}\n\nfor a in links:\n    y+=1\n    url='https://ontheroadtovote.com/ncaaf/fcs/'+a['href']\n    \n    if '.txt' in str(a) and 'teams' not in str(a):\n        df=pd.read_csv(url)\n        df=df.replace(\"Eastern Washngton\",\"Eastern Washington\")\n        df=df.replace(\"Nofrolk State\",'Norfolk State')\n        for row in df.itertuples():\n            if row.Schl not in pts:\n                pts[row.Schl]=0\n                \n            if 'Year' in str(row):\n                s=row.Year \n            if 'Season' in str(row):\n                s=row.Season\n            if 'season' in str(row):\n                s=row.season\n            if 'netural' in str(row):\n                n=row.netural\n            if 'neutral' in str(row):\n                n=row.neutral\n            schl=str(row.Schl)\n            opp=str(row.Opp)\n            didf=0\n            if 'for' in schl:\n                schl=schl.split(\"(\")\n                schl=schl[0]\n                if row.PTS==1 and row.OPP==0:\n                    didf=1\n                if row.PTS==0 and row.OPP==1:\n                    didf=1\n            if 'for' in opp:\n                opp=opp.split(\"(\")\n                opp=opp[0]\n                if row.PTS==1 and row.OPP==0:\n                    didf=1\n                if row.PTS==0 and row.OPP==1:\n                    didf=1\n            if float(s)<1995:\n                na=row.Opp+row.Schl+row.Date+str(row.OPP)+str(row.PTS)\n            \n                if na not in arrz:\n                    if row.Schl in teams[float(s)]:\n                        inarr=1\n                        if didf==0:\n                            arrz.append(row.Schl+row.Opp+row.Date+str(row.PTS)+str(row.OPP))\n                            arr.append([schl,opp,row.Venue,row.PTS,row.OPP,row.Date,s,n])\n                        \n        \ndf=pd.concat([pd.DataFrame(arr)])\ndf.columns=['Schl','Opp','Venue','PTS',\"OPP\",'date','Season','neutral']\ndf=df[df.Season<1995]\ndf.sort_values(by='date') \nfor row in df.itertuples():\n    if row.Opp not in pts:\n        pts[row.Opp]=0\n    pts[row.Schl]+=float(row.PTS)\n    pts[row.Opp]+=float(row.OPP)\n    g=str(row.Schl)\n    g=g.rstrip()\n        \n    gz=str(row.Opp)\n    gz=gz.rstrip()\n    df.at[row.Index,'Schl']=g\n    df.at[row.Index,'Opp']=gz\ndf=df.rename(columns={'Schl':'home','Opp':\"away\",\"PTS\":\"homep\",'OPP':'awayp','Season':'season','Venue':'venue1'})\nfcs=df\nfcs=fcs.replace(\"Nicholls State State\",\"Nicholls State\")\nfcs=fcs.replace(\"Middle Tennessee State State\",\"Middle Tennessee State\")\nfcs=fcs.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\nfcs['date']= pd.to_datetime(fcs['date'])\nprint(\"didfcs\")\n\nr = requests.get('https://ontheroadtovote.com/ncaaf/fbsteams.json')\ny=r.json()\nnccaa=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/nccaafootball.csv\")\n\nfile=fcs\nteamsf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/teams.txt\")\nteamz={}\nfile=file.astype(\"string\")\nfile.reset_index(inplace=True)\nfile['home'].str.replace(' ', '')\nfile['away'].str.replace(' ', '')\nfile['home']=file['home'].replace(\"Charleston So \",\"Charleston Southern\")\nfile['home']=file['home'].str.rstrip()\nfile['away']=file['away'].str.rstrip()\nfile['away']=file['away'].replace(\"Charleston So \",\"Charleston Southern\")\nteamw={}\nteamw['Charleston So']='Charleston Southern'\ny=[]\nga=[]\nthiss=pd.DataFrame(z)\nthiss=thiss[thiss.season==2023]\nfor row in thiss.itertuples():\n    ga.append([row.home,row.away,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\nfor row in file.itertuples():\n    g=str(row.home)\n    g=g.rstrip()\n        \n    gz=str(row.away)\n    gz=gz.rstrip()\n    file.at[row.Index,'home']=g\n    file.at[row.Index,'away']=gz\n\nfile['home'] = file.home.str.replace('_', ' ')\nfile['away'] = file.away.str.replace('_', ' ')\n\n\nfcsa=[]\ncss=2023\n\nfrom2000=from2000.replace(\"]\",\"\")\nfrom2000=from2000.replace(\"[\",\"\")\nfrom2000=from2000.astype({'season':float,'homep':float,'awayp':float})\nfrom2000=from2000.drop_duplicates()\nfrom2000.sort_values(by='date',inplace=True)\nfrom2000=from2000\n\nfrom2000['date'] = pd.to_datetime(from2000['date'], errors='coerce',utc=True)\n\nfrom2000['date'] = pd.to_datetime(from2000.date,utc=True)\nfrom2000['date'] = from2000['date'].dt.strftime('%Y-%m-%d')\ncurrd=from2000\ncurrteams=set(currd.home.tolist()+currd.away.tolist())\nallconfs={}\nprint('ready')\nimport requests\nw=0\nl=0\nregm=0\ndf=dfz\ncurrSeason=1869\nfrom20000=from2000\ny=0\ndobye=0\ndc=0\nrev=(0.30)\ntds={}\nga=[]\nimport requests\nnames=set()\nreplace=requests.get(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/teams.json\")\nreplace=replace.json()\nreplace2=requests.get(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/teams1.json\")\nreplace2=replace2.json()\nreplace3=requests.get(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/teams2.json\")\nreplace3=replace3.json()\nfcs=pd.concat([pd.DataFrame(arr)])\nfcs.columns=['home','away','venue','homep','awayp','date','season','neutral']\nfor row in fcs.itertuples():\n    \n    ht=row.home\n    at=row.away\n    if ht in replace:\n        ht=replace[ht]\n    if at in replace:\n        at=replace[at]\n    if ht in replace2:\n        ht=replace2[ht]\n    if at in replace2:\n        at=replace2[at]\n    if ht in replace3:\n        ht=replace3[ht]\n    if at in replace3:\n        at=replace3[at]\n    name=row.away+row.date+row.home\n    if name not in names:\n            \n        ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,row.venue])\n    names.add(name)\nz=pd.DataFrame(z)\nfiles=['usportsscores.csv','fcsscores.csv',\"updatedd2scores.csv\",\"updatedd3scores.csv\",\"naiascores.csv\",\"nccaascores.csv\",\"njcaascores.csv\",'cccaascores.csv',\"2013d3.txt\",\"2013naia.txt\"]\nfor file in files:\n    df=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/\"+file)\n    if file=='2013d3.txt':\n        df['Year']=2013\n        df['Venue']='vs'\n        df.columns=['Opp','Schl','neutral','PTS','OPP','Date','Year','Venue']\n    if file=='2013naia.txt':\n        df['Year']=2013\n    for row in df.itertuples():\n        \n        ht=row.Schl\n        at=row.Opp\n        if ht in replace:\n            ht=replace[ht]\n        if at in replace:\n            at=replace[at]\n        if ht in replace2:\n            ht=replace2[ht]\n        if at in replace2:\n            at=replace2[at]\n        if ht in replace3:\n            ht=replace3[ht]\n        if at in replace3:\n            at=replace3[at]\n        name=row.Opp+row.Date+row.Schl\n        if name not in names:\n            ga.append([ht,at,row.neutral,row.Year,row.Date,row.PTS,row.OPP,row.Venue])\n            \n        \n        names.add(name)\n    \n\nfor row in fcs.itertuples():\n    \n    ht=row.home\n    at=row.away\n    if ht in replace:\n        ht=replace[ht]\n    if at in replace:\n        at=replace[at]\n    if ht in replace2:\n        ht=replace2[ht]\n    if at in replace2:\n        at=replace2[at]\n    if ht in replace3:\n        ht=replace3[ht]\n    if at in replace3:\n        at=replace3[at]\n    name=row.away+row.date+row.home\n    if name not in names:\n            \n        ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,\"vs\"])\n    names.add(name)\nz.columns=['home','homeconf','homep','away','awayconf','awayp','attendance','neutral','season','playoff','date','week','id','season_type']\nfor row in z.itertuples():\n    ht=row.home\n    at=row.away\n    if ht in replace:\n        ht=replace[ht]\n    if at in replace:\n        at=replace[at]\n    if ht in replace2:\n        ht=replace2[ht]\n    if at in replace2:\n        at=replace2[at]\n    if ht in replace3:\n        ht=replace3[ht]\n    if at in replace3:\n        at=replace3[at]\n    name=row.away+row.date+row.home\n    if name not in names:\n            \n        ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,\"vs\"])\n    names.add(name)\nfcsdf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/fcsscores.csv\")\n\nfor row in dfz.itertuples():\n    ht=row.home\n    at=row.away\n    if ht in replace:\n        ht=replace[ht]\n    if at in replace:\n        at=replace[at]\n    if ht in replace2:\n        ht=replace2[ht]\n    if at in replace2:\n        at=replace2[at]\n    if ht in replace3:\n        ht=replace3[ht]\n    if at in replace3:\n        at=replace3[at]\n    if (row.date>str(\"1995-11-25\"))and float(row.homep)==0 and float(row.awayp)==0:\n        m=1\n    if (row.date<str(\"1995-11-26\"))and float(row.homep)==0 and float(row.awayp)==0:\n        ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\n    \n    \n        \n    if ((float(row.homep)==0 and float(row.awayp)==0)==False):\n        name=row.away+row.date+row.home\n        if name not in names:\n            \n        \n            \n            \n            ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\n        names.add(name)\n    \n    \n    \nfrom2000=pd.DataFrame(ga)\nfrom2000.columns=['home','away','neutral','season','date','homep','awayp','venue1']\nfor season in from2000.season.unique():\n    tds[season]={ }\nfor row in from2000.itertuples():\n    tds[row.season][row.home]='yes'\n    tds[row.season][row.away]='yes'\ndoms=1\ndc=1\nconfm=1\neloLeaguez.addPlayer(\"St John's (NY)\")\neloLeaguez.addPlayer(\"Fairfield\")\nfrom2000=from2000.astype(\"string\")\nfrom2000=from2000.astype({\"homep\":float,'awayp':float,'season':float})\nfrom2000['venue1']=from2000['venue1'].replace(\"-1\",\"@\")\nfrom2000=from2000.replace(\"S Carolina St\",\"South Carolina State\")\nfrom2000['venue1']=from2000['venue1'].replace(\"1\",\"vs\")\nfrom2000=from2000.drop_duplicates()\nfrom2000['date']=from2000.date.str.replace(\"'\",\"\")\nfrom2000.sort_values(by='date',inplace=True)\nfrom20000=from2000\nfrom2000=from2000[from2000.date<str(today)]\nfrom2000=from2000[from2000.homep.notna()]\nfrom2000=from2000[from2000.awayp.notna()]\nr = requests.get('https://ontheroadtovote.com/ncaaf/fbsteams.json')\ny=r.json()\nnaiadf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/naiastandings1969-1994.csv\")\nnaiadf=naiadf[['Team','Wins','Losses','Season']]\nnaiadf=naiadf.replace(\"/NR\",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"/NR\",\"\")\nfor team in y:\n    from2000=from2000.replace(team,y[team])\ncoldiv=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/collegedivision.csv\")\ny=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/collegedivteams.json\")\ny=y.json()\ncoldiv['Team']=coldiv.Team.str.replace(\"/0 \",\"\")\ncoldiv['Team']=coldiv.Team.str.replace(\"UPI \",\"\")\ncoldiv['Team']=coldiv.Team.str.replace(\"AP / No. \",\"\")\ncoldiv['Team']=coldiv.Team.str.replace(\"/NR\",\"\")\ncoldiv['Team']=coldiv.Team.str.replace(\"†\",\"\")\ncoldiv['Team']=coldiv.Team.str.replace(\"3\",\"\")\ncoldiv['Team']=coldiv.Team.str.replace(\"–\",\"-\")\ncoldiv['Team']=coldiv.Team.str.strip()\ncoldiv['Team']=coldiv['Team'].astype(\"str\")\nfor team in y:\n    coldiv['Team']=coldiv['Team'].replace(team,y[team])\nd2df=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d2footballstandings.csv\")\ny=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/d2footballteams.json\")\ny=y.json()\nd2df['Team']=d2df.Team.str.replace(\"/0 \",\"\")\nd2df['Team']=d2df.Team.str.replace(\"UPI \",\"\")\nd2df['Team']=d2df.Team.str.replace(\"AP / No. \",\"\")\nd2df['Team']=d2df.Team.str.replace(\"/NR\",\"\")\nd2df['Team']=d2df.Team.str.replace(\"†\",\"\")\nd2df['Team']=d2df.Team.str.replace(\"3\",\"\")\nd2df['Team']=d2df.Team.str.replace(\"–\",\"-\")\nd2df['Team']=d2df.Team.str.strip()\nd2df['Team']=d2df['Team'].astype(\"str\")\nfor team in y:\n    d2df['Team']=d2df['Team'].replace(team,y[team])\nd3df=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d3footballstandings.csv\")\ny=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/d3footballteams.json\")\ny=y.json()\nd3df['Team']=d3df.Team.str.replace(\"/0 \",\"\")\nd3df['Team']=d3df.Team.str.replace(\"UPI \",\"\")\nd3df['Team']=d3df.Team.str.replace(\"AP / No. \",\"\")\nd3df['Team']=d3df.Team.str.replace(\"/NR\",\"\")\nd3df['Team']=d3df.Team.str.replace(\"†\",\"\")\nd3df['Team']=d3df.Team.str.replace(\"3\",\"\")\nd3df['Team']=d3df.Team.str.replace(\"–\",\"-\")\nd3df['Team']=d3df.Team.str.strip()\nd3df['Team']=d3df['Team'].astype(\"str\")\n\nfor team in y:\n    d3df['Team']=d3df['Team'].replace(team,y[team])\nd3df=d3df.dropna()\nd3df=d3df.replace(\"xa\",\"\")\nd3df=d3df[d3df.Losses!='–']\nr = requests.get('https://ontheroadtovote.com/ncaaf/fcs/teams.json')\ny=r.json()\n\nfor team in y:\n    from2000=from2000.replace(team,y[team])\nteams=set(d2df.Team.tolist())\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nteams=set(d3df.Team.tolist())\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nteams=set(from2000.home.tolist()+from2000.away.tolist())\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nnaiadf=naiadf[naiadf.Wins!=\"?\"]\nnaiadf=naiadf[naiadf.Losses!=\"?\"]\nnaiadf=naiadf.astype({\"Team\":\"string\",\"Wins\":float,\"Losses\":float,\"Season\":float})\nnaiadf=naiadf.drop_duplicates()\nteams=set(naiadf.Team.tolist())\n\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nteams=set(coldiv.Team.tolist())\n\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nfcss=[]\nfcsvnon=[]\nfrom2000=from2000.drop_duplicates()\nfor game in from2000.itertuples():\n    if game.season>1977:\n        if game.home in str(fbsteams[game.season]) and game.away in str(teamzzz[game.season]):\n            fcss.append(game.awayp-game.homep)\n        if game.away in str(fbsteams[game.season]) and game.home in str(teamzzz[game.season]):\n            fcss.append(game.homep-game.awayp)\n        if game.away not in str(fbsteams[game.season]) and game.away not in str(teamzzz[game.season]) and game.home in str(teamzzz[game.season]):\n            fcsvnon.append(game.homep-game.awayp)\n        if game.home not in str(fbsteams[game.season]) and game.home not in str(teamzzz[game.season]) and game.away in str(teamzzz[game.season]):\n            fcsvnon.append(game.awayp-game.homep)\nnaiateams={}\nfor i in range(1969,1995):\n    naiateams[float(i)]={}\n\nfor row in naiadf.itertuples():\n    naiateams[row.Season][row.Team]={}\n    naiateams[row.Season][row.Team]['W']=float(row.Wins)\n    naiateams[row.Season][row.Team]['L']=float(row.Losses)\nd2teams={}\nfor i in range(1969,1995):\n    d2teams[float(i)]={}\n\nfor row in d2df.itertuples():\n    d2teams[row.Season][row.Team]={}\n    d2teams[row.Season][row.Team]['W']=float(row.Wins)\n    d2teams[row.Season][row.Team]['L']=float(row.Losses)\ncoldivteams={}\nfor i in range(1956,1973):\n    coldivteams[float(i)]={}\n\nfor row in coldiv.itertuples():\n    coldivteams[row.Season][row.Team]={}\n    coldivteams[row.Season][row.Team]['W']=float(row.Wins)\n    coldivteams[row.Season][row.Team]['L']=float(row.Losses)\nd3teams={}\nfor i in range(1973,1995):\n    d3teams[float(i)]={}\n\nfor row in d3df.itertuples():\n    d3teams[row.Season][row.Team]={}\n    d3teams[row.Season][row.Team]['W']=float(row.Wins)\n    d3teams[row.Season][row.Team]['L']=float(row.Losses)  \nfor game in from2000.itertuples():\n    fcs=abs(round(np.mean(fcss))*20)*2\n    fcsv=abs(round(np.mean(fcsvnon))*20)*2\n    hpen=0\n    apen=0\n    if game.season>1977:\n        if game.away not in str(fbsteams[game.season]) and game.away not in str(teamzzz[game.season]) and game.home in str(teamzzz[game.season]):\n            apen=fcsv\n        if game.home not in str(fbsteams[game.season]) and game.home not in str(teamzzz[game.season]) and game.away in str(teamzzz[game.season]):\n            hpen=fcsv\n        if game.home in str(fbsteams[game.season]) and game.away in str(teamzzz[game.season]):\n            apen=fcs\n        if game.away in str(fbsteams[game.season]) and game.home in str(teamzzz[game.season]):\n            hpen=fcs\n    season=game.season\n    if (season >currSeason):\n        if season>1955 and season<1973:\n            for team in coldivteams[game.season]:\n                \n                if team not in ct:\n                    wins=coldivteams[game.season][team]['W']*20\n                    losses=coldivteams[game.season][team]['L']*20\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    eloLeaguez.ratingDict[team]+=wins\n                    eloLeaguez.ratingDict[team]-=losses\n        if season>1968 and season<1995:\n            for team in naiateams[game.season]:\n                \n                if team not in ct:\n                    wins=naiateams[game.season][team]['W']*20\n                    losses=naiateams[game.season][team]['L']*20\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    eloLeaguez.ratingDict[team]+=wins\n                    eloLeaguez.ratingDict[team]-=losses\n        if season>1972 and season<1995:\n            \n            for team in d3teams[game.season]:\n                \n                if team not in ct:\n                    wins=d3teams[game.season][team]['W']*20\n                    losses=d3teams[game.season][team]['L']*20\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    eloLeaguez.ratingDict[team]+=wins\n                    eloLeaguez.ratingDict[team]-=losses\n        if season>1972 and season<1995:\n            for team in d2teams[game.season]:\n                \n                if team not in ct:\n                    wins=d2teams[game.season][team]['W']*20\n                    losses=d2teams[game.season][team]['L']*20\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    eloLeaguez.ratingDict[team]+=wins\n                    eloLeaguez.ratingDict[team]-=losses\n        lsdf=from2000[from2000.season<game.season]\n        ls=set(lsdf.home.tolist()+lsdf.away.tolist())\n        ctdf=from2000[from2000.season==game.season]\n        ct=set(ctdf.home.tolist()+ctdf.away.tolist())\n        \n        for key in ls:\n            if key in ct:\n                if game.season<1978:\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1500) * (1/3.))\n                if game.season>1977:\n                    if key in str(fbsteams[game.season]):\n                        \n                        eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1500) * (1/3.))\n                    if key in str(teamzzz[game.season]):\n                        eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    if key not in str(teamzzz[game.season]) and key not in str(fbsteams[game.season]):\n                        eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n\n        currSeason=game.season\n    if 'vs' in str(game.venue1):\n        \n        ht=game.home\n        at=game.away\n        hp=game.homep\n        ap=game.awayp\n    else:\n        at=game.home\n        ht=game.away\n        ap=game.homep\n        hp=game.awayp\n    if (hp > ap)or(hp==ap):\n        \n        \n    \n        eloLeaguez.gameOver(ht,at,True,game.neutral,hp,ap,hpen,apen)\n    \n    \n    if ap>hp:\n        \n        eloLeaguez.gameOver(at, ht,False,game.neutral,ap,hp,apen,hpen)\nprint(\"{\")\na=0\ntp=0\nfor team in eloLeaguez.ratingDict.keys():\n  if tp==1:\n      my=[]\n      print(team,\":\",eloLeaguez.ratingDict[team])\ntxtz='\"','Team','\"',':','20'\nprint('\"','Team','\"',':','20')\nprint(\"}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-09T23:59:09.615285Z","iopub.execute_input":"2024-03-09T23:59:09.615895Z","iopub.status.idle":"2024-03-10T00:14:05.893686Z","shell.execute_reply.started":"2024-03-09T23:59:09.615852Z","shell.execute_reply":"2024-03-10T00:14:05.892209Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\ndidfcs\nready\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:581: FutureWarning: The default value of regex will change from True to False in a future version.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:595: FutureWarning: The default value of regex will change from True to False in a future version.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:609: FutureWarning: The default value of regex will change from True to False in a future version.\n","output_type":"stream"},{"name":"stdout","text":"{\n\" Team \" : 20\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"q=from2000[from2000.away=='Langston']\nq[q.season==2013]","metadata":{"execution":{"iopub.status.busy":"2024-03-10T00:23:54.164523Z","iopub.execute_input":"2024-03-10T00:23:54.165005Z","iopub.status.idle":"2024-03-10T00:23:54.224515Z","shell.execute_reply.started":"2024-03-10T00:23:54.164969Z","shell.execute_reply":"2024-03-10T00:23:54.222898Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"                                  home      away neutral  season  \\\n165628               Northern Colorado  Langston   False  2013.0   \n165921                  Incarnate Word  Langston    True  2013.0   \n166048                        Nicholls  Langston   False  2013.0   \n166140              Northwestern State  Langston   False  2013.0   \n77843   Southwestern Assemblies of God  Langston   False  2013.0   \n77873                    Texas College  Langston   False  2013.0   \n77857                   Bacone College  Langston   False  2013.0   \n77885                  Wayland Baptist  Langston   False  2013.0   \n\n                            date  homep  awayp venue1  \n165628  2013-08-31T19:35:00.000Z   31.0   10.0     vs  \n165921  2013-09-14T23:00:00.000Z   24.0    0.0     vs  \n166048  2013-09-21T23:00:00.000Z   42.0   22.0     vs  \n166140  2013-09-28T23:00:00.000Z   37.0    0.0     vs  \n77843                 2013-10-12   17.0   41.0     vs  \n77873                 2013-10-19    8.0   34.0      @  \n77857                 2013-11-09   37.0   39.0     vs  \n77885                 2013-11-16    0.0   33.0      @  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home</th>\n      <th>away</th>\n      <th>neutral</th>\n      <th>season</th>\n      <th>date</th>\n      <th>homep</th>\n      <th>awayp</th>\n      <th>venue1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>165628</th>\n      <td>Northern Colorado</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-08-31T19:35:00.000Z</td>\n      <td>31.0</td>\n      <td>10.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>165921</th>\n      <td>Incarnate Word</td>\n      <td>Langston</td>\n      <td>True</td>\n      <td>2013.0</td>\n      <td>2013-09-14T23:00:00.000Z</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>166048</th>\n      <td>Nicholls</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-09-21T23:00:00.000Z</td>\n      <td>42.0</td>\n      <td>22.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>166140</th>\n      <td>Northwestern State</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-09-28T23:00:00.000Z</td>\n      <td>37.0</td>\n      <td>0.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>77843</th>\n      <td>Southwestern Assemblies of God</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-10-12</td>\n      <td>17.0</td>\n      <td>41.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>77873</th>\n      <td>Texas College</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-10-19</td>\n      <td>8.0</td>\n      <td>34.0</td>\n      <td>@</td>\n    </tr>\n    <tr>\n      <th>77857</th>\n      <td>Bacone College</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-11-09</td>\n      <td>37.0</td>\n      <td>39.0</td>\n      <td>vs</td>\n    </tr>\n    <tr>\n      <th>77885</th>\n      <td>Wayland Baptist</td>\n      <td>Langston</td>\n      <td>False</td>\n      <td>2013.0</td>\n      <td>2013-11-16</td>\n      <td>0.0</td>\n      <td>33.0</td>\n      <td>@</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"s=input(\"School\")\nfor key in set(from2000.home.tolist()+from2000.away.tolist()):\n    if s in key:\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T23:44:13.796589Z","iopub.execute_input":"2024-03-09T23:44:13.797080Z","iopub.status.idle":"2024-03-09T23:44:16.479879Z","shell.execute_reply.started":"2024-03-09T23:44:13.797043Z","shell.execute_reply":"2024-03-09T23:44:16.478552Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdin","text":"School Panhandle\n"},{"name":"stdout","text":"OK Panhandle St\n","output_type":"stream"}]},{"cell_type":"code","source":"from2000[from2000.away=='Garden City']","metadata":{"execution":{"iopub.status.busy":"2024-03-09T21:11:09.132376Z","iopub.execute_input":"2024-03-09T21:11:09.132822Z","iopub.status.idle":"2024-03-09T21:11:09.182302Z","shell.execute_reply.started":"2024-03-09T21:11:09.132785Z","shell.execute_reply":"2024-03-09T21:11:09.181045Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"            home         away neutral  season                      date  \\\n94543  Lafayette  Garden City   False  1918.0  1918-11-28T00:00:00.000Z   \n\n       homep  awayp venue1  \n94543    0.0   21.0     vs  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home</th>\n      <th>away</th>\n      <th>neutral</th>\n      <th>season</th>\n      <th>date</th>\n      <th>homep</th>\n      <th>awayp</th>\n      <th>venue1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>94543</th>\n      <td>Lafayette</td>\n      <td>Garden City</td>\n      <td>False</td>\n      <td>1918.0</td>\n      <td>1918-11-28T00:00:00.000Z</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>vs</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import requests\nmonths={\"August\":'08','September':\"09\",'October':\"10\",'November':\"11\",'December':\"12\"}\ndays=['Sun.','Sat.','Thu.','Mon.','Fri.']\nheaders={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\nhtml=requests.get(\"https://www.njcaa.org/sports/fball/2013-14/schedule\",headers=headers)\nhtml=html.text\nfrom bs4 import BeautifulSoup\nsoup=BeautifulSoup(html)\ntable=soup.find_all(\"table\")[0]\nnum=0\ngames=[]\ndidp=0\nnotes=table.find_all(\"td\",{\"class\":\"e_notes\"})\nfor tr in table.find_all(\"tr\"):\n    \n    if 'month' in str(tr):\n        month=tr.text\n    \n    if num!=0 and 'month' not in str(tr) and 'notes' not in str(tr):\n        if \"\\xa0\" in td[0].text:\n            m=1\n        else:\n            day=td[0].text\n        date=\"2013\"+month+day\n        td=tr.find_all(\"td\")\n        away=td[1].text\n        away=away.strip()\n        aways=td[2].text\n        aways=aways.strip()\n        home=td[3].text\n        home=home.strip()\n        homes=td[4].text\n        homes=homes.strip()\n        notes=table.find_all(\"tr\")[num+1]\n        notes=notes.text\n        note=notes\n        n=False\n        for dayz in days:\n            date=date.replace(dayz,\"\")\n        for m in months:\n            date=date.replace(m,months[m])\n        if(homes==0 and aways==1) or(homes==0 and aways==1):\n            m=1\n        else:\n            date=date.replace(\" \",\"\")\n            if 'Scrimmage' not in note and 'Final' in str(tr):\n                if '@' in str(note):\n                    n=True\n                away=away.replace(\"\\n\",\"\")\n                home=home.replace(\"\\n\",\"\")\n                aways=aways.replace(\"\\n\",\"\")\n                homes=homes.replace(\"\\n\",\"\")\n                n=str(n)\n                n=n.replace(\"\\n\",\"\")\n                date=date.replace(\"\\n\",\"\")\n                row=[away,aways,home,homes,n,date]\n                \n                \n                games.append(row)\n                    \n            \n            didp=1\n    num+=1","metadata":{"execution":{"iopub.status.busy":"2024-03-09T20:38:49.947078Z","iopub.execute_input":"2024-03-09T20:38:49.947530Z","iopub.status.idle":"2024-03-09T20:38:54.735617Z","shell.execute_reply.started":"2024-03-09T20:38:49.947490Z","shell.execute_reply":"2024-03-09T20:38:54.734411Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/2013naia.txt\")\nreplace=requests.get(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/teams.json\")\nreplace=replace.json()\nreplace2=requests.get(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/teams1.json\")\nreplace2=replace2.json()\nreplace3=requests.get(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/teams2.json\")\nreplace3=replace3.json()\ndf['Year']=2013\nfor team in set(df.Schl.tolist()+df.Opp.tolist()):\n    if team in replace:\n        team=replace[team]\n    if team in replace2:\n        team=replace2[team]\n    if team in replace3:\n        team=replace3[team]\n    if team not in eloLeaguez.ratingDict.keys():\n        print(team)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T23:49:22.092917Z","iopub.execute_input":"2024-03-09T23:49:22.093413Z","iopub.status.idle":"2024-03-09T23:49:24.262743Z","shell.execute_reply.started":"2024-03-09T23:49:22.093378Z","shell.execute_reply":"2024-03-09T23:49:24.261388Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"Sterling\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-09T23:49:26.106682Z","iopub.execute_input":"2024-03-09T23:49:26.107130Z","iopub.status.idle":"2024-03-09T23:49:26.128135Z","shell.execute_reply.started":"2024-03-09T23:49:26.107096Z","shell.execute_reply":"2024-03-09T23:49:26.126982Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"           Date      Schl                             Opp Venue  PTS  OPP  \\\n0    2013-10-12  Langston  Southwestern Assemblies of God     @   41   17   \n1    2013-10-19  Langston                   Texas College    vs   34    8   \n2    2013-10-26  Langston                Oklahoma Baptist    vs   53    7   \n3    2013-11-02  Langston                 OK Panhandle St     @   20   19   \n4    2013-11-09  Langston                          Bacone     @   39   37   \n..          ...       ...                             ...   ...  ...  ...   \n883  2013-09-28    Warner                       Ave Maria    vs    3   27   \n884  2013-10-12    Warner               Southern Virginia     @   20   35   \n885  2013-10-19    Warner               Alderson-Broaddus    vs   14   51   \n886  2013-10-26    Warner                    Florida Tech     @    3   37   \n887  2013-11-16    Warner                  Concordia (AL)     @   13    7   \n\n    neutral  Year  \n0     False  2013  \n1     False  2013  \n2     False  2013  \n3     False  2013  \n4     False  2013  \n..      ...   ...  \n883   False  2013  \n884   False  2013  \n885   False  2013  \n886   False  2013  \n887   False  2013  \n\n[888 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Schl</th>\n      <th>Opp</th>\n      <th>Venue</th>\n      <th>PTS</th>\n      <th>OPP</th>\n      <th>neutral</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-10-12</td>\n      <td>Langston</td>\n      <td>Southwestern Assemblies of God</td>\n      <td>@</td>\n      <td>41</td>\n      <td>17</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013-10-19</td>\n      <td>Langston</td>\n      <td>Texas College</td>\n      <td>vs</td>\n      <td>34</td>\n      <td>8</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013-10-26</td>\n      <td>Langston</td>\n      <td>Oklahoma Baptist</td>\n      <td>vs</td>\n      <td>53</td>\n      <td>7</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013-11-02</td>\n      <td>Langston</td>\n      <td>OK Panhandle St</td>\n      <td>@</td>\n      <td>20</td>\n      <td>19</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013-11-09</td>\n      <td>Langston</td>\n      <td>Bacone</td>\n      <td>@</td>\n      <td>39</td>\n      <td>37</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>2013-09-28</td>\n      <td>Warner</td>\n      <td>Ave Maria</td>\n      <td>vs</td>\n      <td>3</td>\n      <td>27</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>884</th>\n      <td>2013-10-12</td>\n      <td>Warner</td>\n      <td>Southern Virginia</td>\n      <td>@</td>\n      <td>20</td>\n      <td>35</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>2013-10-19</td>\n      <td>Warner</td>\n      <td>Alderson-Broaddus</td>\n      <td>vs</td>\n      <td>14</td>\n      <td>51</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>2013-10-26</td>\n      <td>Warner</td>\n      <td>Florida Tech</td>\n      <td>@</td>\n      <td>3</td>\n      <td>37</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>2013-11-16</td>\n      <td>Warner</td>\n      <td>Concordia (AL)</td>\n      <td>@</td>\n      <td>13</td>\n      <td>7</td>\n      <td>False</td>\n      <td>2013</td>\n    </tr>\n  </tbody>\n</table>\n<p>888 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"fcsu={\"1995\":\"https://masseyratings.com/scores.php?s=41840&sub=11605&all=1\",\"1996\":\"https://masseyratings.com/scores.php?s=41841&sub=11605&all=1\",\"1997\":\"https://masseyratings.com/scores.php?s=41842&sub=11605&all=1\",\"1998\":\"https://masseyratings.com/scores.php?s=41843&sub=11605&all=1\",\"1999\":\"https://masseyratings.com/scores.php?s=41844&sub=11605&all=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=11605&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=11605&all=1\"}\nggg=[]\nd3={\"1995\":\"https://masseyratings.com/scores.php?s=41840&sub=11620&all=1\",\"1996\":\"https://masseyratings.com/scores.php?s=41841&sub=11620&all=1\",\"1997\":\"https://masseyratings.com/scores.php?s=41842&sub=11620&all=1\",\"1998\":\"https://masseyratings.com/scores.php?s=41843&sub=11620&all=1\",\"1999\":\"https://masseyratings.com/scores.php?s=41844&sub=11620&all=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=11620&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=11620&all=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=11620&all=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=11620&all=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=11620&all=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=11620&all=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=11620&all=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=11620&all=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=11620&all=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=11620&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=11620&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=11620&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=11620&all=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=11620&all=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=11620&all=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=11620&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=11620&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=11620&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=11620&all=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=11620&all=1\"}\nusports={\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=10909&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=10909&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=10909&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=10909&all=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=10909&all=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=10909&all=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=10909&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=10909&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=10909&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=10909&all=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=10909&all=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=10909&all=1\",\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=10909&all=1\"}\nd3={\"1995\":\"https://masseyratings.com/scores.php?s=41840&sub=11620&all=1\",\"1996\":\"https://masseyratings.com/scores.php?s=41841&sub=11620&all=1\",\"1997\":\"https://masseyratings.com/scores.php?s=41842&sub=11620&all=1\",\"1998\":\"https://masseyratings.com/scores.php?s=41843&sub=11620&all=1\",\"1999\":\"https://masseyratings.com/scores.php?s=41844&sub=11620&all=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=11620&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=11620\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=11620&all=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=11620&all=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=11620&all=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=11620&all=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=11620&all=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=11620&all=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=11620&all=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=11620&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=11620&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=11620&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=11620&all=1\"}\nnaia={\"1995\":\"https://masseyratings.com/scores.php?s=41840&sub=12795&all=1\",\"1996\":\"https://masseyratings.com/scores.php?s=41841&sub=12795&all=1\",\"1997\":\"https://masseyratings.com/scores.php?s=41842&sub=12795&all=1\",\"1998\":\"https://masseyratings.com/scores.php?s=41843&sub=12795&all=1\",\"1999\":\"https://masseyratings.com/scores.php?s=41844&sub=12795&all=1\",\"1999\":\"https://masseyratings.com/scores.php?s=41844&sub=12795&all=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=12795&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=12795&all=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=12795&all=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=12795&all=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=12795&all=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=12795&all=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=12795&all=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=12795&all=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=12795&all=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=12795&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=12795&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=12795&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=12795&all=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=12795&all=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=12795&all=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12795&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12795&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12795&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12795&all=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=12795&all=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12795&all=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12795&all=1\",\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12795&all=1\"}\nd2={\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=11606&all=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=11606&all=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=11606&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=11606&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=11606&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=11606&all=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=11606&all=1\",\"1995\":\"https://masseyratings.com/scores.php?s=41840&sub=11606&all=1\",\"1996\":\"https://masseyratings.com/scores.php?s=41841&sub=11606&all=1\",\"1997\":\"https://masseyratings.com/scores.php?s=41842&sub=11606&all=1\",\"1998\":\"https://masseyratings.com/scores.php?s=41843&sub=11606&all=1\",\"1999\":\"https://masseyratings.com/scores.php?s=41844&sub=11606&all=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=11606&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=11606&all=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=11606&all=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=11606&all=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=11606&all=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=11606&all=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=11606&all=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=11606&all=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=11606&all=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=11606&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=11606&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=11606&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=11606&all=1\"}\nnccaa={\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12799&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12799&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12799&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12799&all=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=12799&all=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12799&all=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12799&all=1\",\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12799&all=1\"}\nimport re\ncccaa={\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=95204&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=95204&all=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=95204&all=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=95204&all=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=95204&all=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=95204&all=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=95204&all=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=95204&all=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=95204&all=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=95204&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=95204&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=95204&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=95204&all=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=95204&all=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=95204&all=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=95204&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=95204&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=95204&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=95204&all=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=95204&all=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=95204&all=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=95204&all=1\",\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=95204&all=1\"}\nnjcaa={\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=12814&all=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=12814&all=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=12814&all=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=12814&all=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=12814&all=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=12814&all=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=12814&all=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=12814&all=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=12814&all=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=12814&all=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=12814&all=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=12814&all=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=12814&all=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=12814&all=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=12814&all=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12814&all=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12814&all=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12814&all=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12814&all=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=12814&all=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12814&all=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12814&all=1\",\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12814&all=1\"}\nimport requests\nfrom bs4 import BeautifulSoup\nfor key in d3:\n    nof=d3[key]\n    \n    nof=str(nof)\n    nof=nof.split(\"&format=\")\n    nof=nof[0]\n    nof=nof+\"&mode=3&format=2\"\n    htmlz=requests.get(nof).text\n    soupz=BeautifulSoup(htmlz)\n    \n    \n    for line in soupz.text.split('\\n')[:-1]:\n        k=str(line)\n        k=k.replace(\" \",\"\")\n        k=k.split(\",\")\n        string=str(k[0])\n        string=string.replace(\" \",\"\")\n    \n    gg=[]\n   \n    r = requests.get(d3[key])\n    soup = BeautifulSoup(r.text, 'lxml')\n    \n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(BeautifulSoup(r.text, 'lxml'))\n    aa=str(aa)\n    aa=(aa.split(\"<hr/><pre>\")[1])\n    \n    aa=aa.replace(\"               \",\",\")\n    aa=aa.replace(\"  \",\",\")\n    for i in range(0,10):\n        aa=aa.replace(str(i)+\" \",str(i)+\",\")\n        \n    aa=aa.replace(\",,,,,,\",\",\")\n    \n    q=aa\n    \n    \n    q=q.split(\"\\n\")\n    for line in q:\n        \n        \n        \n        \n        \n        line=str(line)\n        \n        \n        \n        \n        if 'Games' not in str(line) and str(line)!='' and '<' not in str(line):\n            \n            j=line[1]\n            n=False\n            line = list(line.split(','))\n            v=\"vs\"\n            if \"@\" not in str(line):\n                n=True\n            \n            if \"@\" in str(line[4]):\n                v=\"@\"\n            if \"@\" in str(line[1]):\n                v=\"vs\"\n            date=str(line[0])\n            \n            line=str(line)\n            line=line.replace(\"[\",\"\")\n            line=line.replace(\"]\",\"\")\n            line=line.replace(\"'\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\",@\",\",\")\n            line=line.replace(\"@\",\"\")\n            line = list(line.split(','))\n            lines=[]\n            for l in line:\n                if l==' ' :\n                    m=1\n                else:\n                    \n                    lines.append(l)\n                \n            \n            line=lines\n            s=line[1]\n            s=s.lstrip()\n            s=s.rstrip()\n            o=line[3]\n            o=o.lstrip()\n            o=o.rstrip()\n            row=[date,v,s,o,line[2],line[4],n,key]\n            \n            \n            gg.append(row)\n            ggg.append(row)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T03:34:24.389212Z","iopub.execute_input":"2024-03-09T03:34:24.389934Z","iopub.status.idle":"2024-03-09T03:34:50.977323Z","shell.execute_reply.started":"2024-03-09T03:34:24.389885Z","shell.execute_reply":"2024-03-09T03:34:50.975909Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"naia","metadata":{"execution":{"iopub.status.busy":"2024-03-08T02:17:53.990466Z","iopub.execute_input":"2024-03-08T02:17:53.990987Z","iopub.status.idle":"2024-03-08T02:17:53.999828Z","shell.execute_reply.started":"2024-03-08T02:17:53.990946Z","shell.execute_reply":"2024-03-08T02:17:53.998546Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'1995': 'https://masseyratings.com/scores.php?s=41840&sub=12795&all=1',\n '1996': 'https://masseyratings.com/scores.php?s=41841&sub=12795&all=1',\n '1997': 'https://masseyratings.com/scores.php?s=41842&sub=12795&all=1',\n '1998': 'https://masseyratings.com/scores.php?s=41843&sub=12795&all=1',\n '1999': 'https://masseyratings.com/scores.php?s=41844&sub=12795&all=1',\n '2000': 'https://masseyratings.com/scores.php?s=41845&sub=12795&all=1',\n '2001': 'https://masseyratings.com/scores.php?s=41846&sub=12795&all=1',\n '2002': 'https://masseyratings.com/scores.php?s=41847&sub=12795&all=1',\n '2003': 'https://masseyratings.com/scores.php?s=41848&sub=12795&all=1',\n '2004': 'https://masseyratings.com/scores.php?s=41849&sub=12795&all=1',\n '2005': 'https://masseyratings.com/scores.php?s=41850&sub=12795&all=1',\n '2006': 'https://masseyratings.com/scores.php?s=68033&sub=12795&all=1',\n '2007': 'https://masseyratings.com/scores.php?s=73929&sub=12795&all=1',\n '2008': 'https://masseyratings.com/scores.php?s=85513&sub=12795&all=1',\n '2009': 'https://masseyratings.com/scores.php?s=94988&sub=12795&all=1',\n '2010': 'https://masseyratings.com/scores.php?s=98700&sub=12795&all=1',\n '2011': 'https://masseyratings.com/scores.php?s=107811&sub=12795&all=1',\n '2012': 'https://masseyratings.com/scores.php?s=181623&sub=12795&all=1',\n '2014': 'https://masseyratings.com/scores.php?s=262657&sub=12795&all=1',\n '2015': 'https://masseyratings.com/scores.php?s=279541&sub=12795&all=1',\n '2016': 'https://masseyratings.com/scores.php?s=286577&sub=12795&all=1',\n '2017': 'https://masseyratings.com/scores.php?s=295489&sub=12795&all=1',\n '2018': 'https://masseyratings.com/scores.php?s=300937&sub=12795&all=1',\n '2019': 'https://masseyratings.com/scores.php?s=308075&sub=12795&all=1',\n '2020': 'https://masseyratings.com/scores.php?s=318889&sub=12795&all=1',\n '2021': 'https://masseyratings.com/scores.php?s=358435&sub=12795&all=1',\n '2022': 'https://masseyratings.com/scores.php?s=384031&sub=12795&all=1',\n '2023': 'https://masseyratings.com/scores.php?s=539277&sub=12795&all=1'}"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.DataFrame(ggg,columns=['Date','Venue','Schl','Opp','PTS','OPP','neutral','Year'])\ndf.to_csv(\"updatedd3scores.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-09T00:24:38.900756Z","iopub.execute_input":"2024-03-09T00:24:38.901555Z","iopub.status.idle":"2024-03-09T00:24:39.042944Z","shell.execute_reply.started":"2024-03-09T00:24:38.901503Z","shell.execute_reply":"2024-03-09T00:24:39.041359Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"df.Year.unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-08T23:09:17.661819Z","iopub.execute_input":"2024-03-08T23:09:17.663258Z","iopub.status.idle":"2024-03-08T23:09:17.671916Z","shell.execute_reply.started":"2024-03-08T23:09:17.663215Z","shell.execute_reply":"2024-03-08T23:09:17.670856Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"array(['2014', '2015', '2016', '2017', '2018', '2019', '2020', '1995',\n       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003',\n       '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011',\n       '2012'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"d3df=d3df.dropna()\nd3df=d3df.replace(\"xa\",\"\")\nd3df[d3df.Wins.str.contains(\"xa\")]","metadata":{"execution":{"iopub.status.busy":"2024-01-03T04:02:06.924306Z","iopub.execute_input":"2024-01-03T04:02:06.924647Z","iopub.status.idle":"2024-01-03T04:02:06.945243Z","shell.execute_reply.started":"2024-01-03T04:02:06.924620Z","shell.execute_reply":"2024-01-03T04:02:06.944150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfh=pd.concat([pd.DataFrame(arr)])\ndfh.columns=['Schl','Opp','Venue','PTS',\"OPP\",'date','Season','neutral']","metadata":{"execution":{"iopub.status.busy":"2024-01-02T21:15:59.835202Z","iopub.execute_input":"2024-01-02T21:15:59.835588Z","iopub.status.idle":"2024-01-02T21:15:59.853705Z","shell.execute_reply.started":"2024-01-02T21:15:59.835560Z","shell.execute_reply":"2024-01-02T21:15:59.852516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eloLeaguez.ratingDict['Mississippi Industrial']","metadata":{"execution":{"iopub.status.busy":"2024-01-03T01:41:33.786559Z","iopub.execute_input":"2024-01-03T01:41:33.786924Z","iopub.status.idle":"2024-01-03T01:41:33.794267Z","shell.execute_reply.started":"2024-01-03T01:41:33.786893Z","shell.execute_reply":"2024-01-03T01:41:33.792951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfh[dfh.Opp=='Eastern Michigan']","metadata":{"execution":{"iopub.status.busy":"2024-01-02T21:23:44.268882Z","iopub.execute_input":"2024-01-02T21:23:44.269261Z","iopub.status.idle":"2024-01-02T21:23:44.286632Z","shell.execute_reply.started":"2024-01-02T21:23:44.269230Z","shell.execute_reply":"2024-01-02T21:23:44.284540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fcsteamz=set(dfh.Schl.tolist()+dfh.Opp.tolist())\ncurrteams=set(from2000.home.tolist()+from2000.away.tolist())\nthedict={}\nfor key in fcsteamz:\n    if key in currteams:\n        \n        thedict[key]='1'\nsorted_dict = {key: value for key, value in sorted(thedict.items())}\nsorted_dict","metadata":{"execution":{"iopub.status.busy":"2024-01-02T21:20:48.783954Z","iopub.execute_input":"2024-01-02T21:20:48.784385Z","iopub.status.idle":"2024-01-02T21:20:49.060964Z","shell.execute_reply.started":"2024-01-02T21:20:48.784353Z","shell.execute_reply":"2024-01-02T21:20:49.059540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom bs4 import BeautifulSoup\nimport requests\nteams={}\narr=[]\nfor i in range(1973,1995):\n    teams[i]=[]\nfor i in range(1973,1995):\n    url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_III_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    my_table=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    index=0     \n    for table in my_table:\n        for j in table.find_all(\"tr\")[1:]:\n            statements=\"Team\" not in str(j) and 'title' not in str(j) and 'legend' not in str(j)\n        \n        \n        \n                    \n            if  'Team' not in str(j) and 'conference' not in str(j) and \"style\" not in str(j) and 'Division' not in str(j) and 'League' not in str(j) and 'legend' not in str(j) and 'header' not in str(j):\n            \n            \n            \n                row_data = j.find_all(\"td\")\n                team=row_data[0].text\n                team=team.replace(\"$\",\"\")\n                team=team.replace(\"\\n\",\"\")\n                team=team.replace(\"xy\",\"\")\n                team=team.replace(\" x\",\"\")\n                team=team.replace(\" y\",\"\")\n                team=team.replace(\"^\",\"\")\n                team=team.replace(\"+\",\"\")\n                team=re.sub(r'^.*?1', '', team)\n                team=re.sub(r'^.*?2', '', team)\n                team=re.sub(r'^.*?3', '', team)\n                team=team.replace(\"*\",\"\")\n                team=team.replace(\"1\",\"\")\n                team=team.replace(\"2\",\"\")\n                team=re.sub(r'^.*?4', '', team)\n                team=re.sub(r'^.*?5', '', team)\n                team=re.sub(r'^.*?6', '', team)\n                team=re.sub(r'^.*?7', '', team)\n                team=re.sub(r'^.*?8', '', team)\n                team=re.sub(r'^.*?9', '', team)\n                team=re.sub(r'^.*?0', '', team)\n                team=team.rstrip()\n                wins=row_data[8].text\n                wins=wins.replace(\"\\n\",\"\")\n                losses=row_data[10].text\n                losses=losses.replace(\"\\n\",\"\")\n                team=team.strip()\n                row = [team,wins,losses,i]\n                arr.append(row)\n                if team not in str(teams):\n                \n                    teams[i].append(team)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T01:44:24.643614Z","iopub.execute_input":"2024-01-03T01:44:24.643997Z","iopub.status.idle":"2024-01-03T01:44:44.067838Z","shell.execute_reply.started":"2024-01-03T01:44:24.643968Z","shell.execute_reply":"2024-01-03T01:44:44.066142Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom bs4 import BeautifulSoup\nimport requests\nteams={}\narr=[]\nfor i in range(1969,1995):\n    teams[i]=[]\nfor i in range(1969,1995):\n    url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NAIA_Division_II_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    my_table=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    index=0     \n    for table in my_table:\n        for j in table.find_all(\"tr\")[1:]:\n            statements=\"Team\" not in str(j) and 'title' not in str(j) and 'legend' not in str(j)\n        \n        \n        \n                    \n            if  'Team' not in str(j) and 'conference' not in str(j) and \"style\" not in str(j) and 'Division' not in str(j) and 'League' not in str(j) and 'legend' not in str(j) and 'header' not in str(j):\n            \n            \n            \n                row_data = j.find_all(\"td\")\n                team=row_data[0].text\n                team=team.replace(\"$\",\"\")\n                team=team.replace(\"\\n\",\"\")\n                team=team.replace(\"xy\",\"\")\n                team=team.replace(\" x\",\"\")\n                team=team.replace(\" y\",\"\")\n                team=team.replace(\"^\",\"\")\n                team=team.replace(\"+\",\"\")\n                team=re.sub(r'^.*?1', '', team)\n                team=re.sub(r'^.*?2', '', team)\n                team=re.sub(r'^.*?3', '', team)\n                team=team.replace(\"*\",\"\")\n                team=team.replace(\"1\",\"\")\n                team=team.replace(\"2\",\"\")\n                team=re.sub(r'^.*?4', '', team)\n                team=re.sub(r'^.*?5', '', team)\n                team=re.sub(r'^.*?6', '', team)\n                team=re.sub(r'^.*?7', '', team)\n                team=re.sub(r'^.*?8', '', team)\n                team=re.sub(r'^.*?9', '', team)\n                team=re.sub(r'^.*?0', '', team)\n                team=team.rstrip()\n                wins=row_data[8].text\n                wins=wins.replace(\"\\n\",\"\")\n                losses=row_data[10].text\n                losses=losses.replace(\"\\n\",\"\")\n                team=team.strip()\n                row = [team,wins,losses,i]\n                arr.append(row)\n                if team not in str(teams):\n                \n                    teams[i].append(team)\nfor i in range(1969,1995):\n    url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NAIA_Division_I_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    my_table=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    index=0 \n    for table in my_table:\n        \n        \n        for j in table.find_all(\"tr\")[1:]:\n            statements=\"Team\" not in str(j) and 'title' not in str(j) and 'legend' not in str(j)\n        \n        \n        \n                    \n            if  'Team' not in str(j) and 'conference' not in str(j) and \"style\" not in str(j) and 'legend' not in str(j) and 'header' not in str(j):\n            \n            \n            \n                row_data = j.find_all(\"td\")\n                team=row_data[0].text\n                team=team.replace(\"$\",\"\")\n                team=team.replace(\"\\n\",\"\")\n                team=team.replace(\"xy\",\"\")\n                team=team.replace(\" x\",\"\")\n                team=team.replace(\" y\",\"\")\n                team=team.replace(\"^\",\"\")\n                team=team.replace(\"*\",\"\")\n                team=team.replace(\"+\",\"\")\n                team=re.sub(r'^.*?1', '', team)\n                team=re.sub(r'^.*?2', '', team)\n                team=re.sub(r'^.*?3', '', team)\n                team=re.sub(r'^.*?4', '', team)\n                team=re.sub(r'^.*?5', '', team)\n                team=re.sub(r'^.*?6', '', team)\n                team=re.sub(r'^.*?7', '', team)\n                team=re.sub(r'^.*?8', '', team)\n                team=re.sub(r'^.*?9', '', team)\n                team=re.sub(r'^.*?0', '', team)\n        \n                team=team.replace(\"1\",\"\")\n                team=team.replace(\"2\",\"\")\n                team=team.rstrip()\n                wins=row_data[8].text\n                wins=wins.replace(\"\\n\",\"\")\n                losses=row_data[10].text\n                losses=losses.replace(\"\\n\",\"\")\n                team=team.strip()\n                row = [team,wins,losses,i]\n                arr.append(row)\n                if team not in str(teams):\n                \n                    teams[i].append(team)\n            \n            \n                    \n                    \n            \n\nnaiad1=teams\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:42:52.752194Z","iopub.execute_input":"2023-12-28T22:42:52.752752Z","iopub.status.idle":"2023-12-28T22:43:25.295459Z","shell.execute_reply.started":"2023-12-28T22:42:52.752704Z","shell.execute_reply":"2023-12-28T22:43:25.294117Z"},"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_data","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:42:31.985266Z","iopub.execute_input":"2023-12-28T22:42:31.985792Z","iopub.status.idle":"2023-12-28T22:42:31.994577Z","shell.execute_reply.started":"2023-12-28T22:42:31.985753Z","shell.execute_reply":"2023-12-28T22:42:31.993127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naiadf.to_csv(\"d2standings.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T00:52:22.210372Z","iopub.execute_input":"2024-01-03T00:52:22.210792Z","iopub.status.idle":"2024-01-03T00:52:22.227910Z","shell.execute_reply.started":"2024-01-03T00:52:22.210756Z","shell.execute_reply":"2024-01-03T00:52:22.226883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=input(\"school\")\nfor key in eloLeaguez.ratingDict.keys():\n    if s in key:\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T03:32:15.295413Z","iopub.execute_input":"2024-03-09T03:32:15.295931Z","iopub.status.idle":"2024-03-09T03:32:17.445174Z","shell.execute_reply.started":"2024-03-09T03:32:15.295891Z","shell.execute_reply":"2024-03-09T03:32:17.443913Z"},"trusted":true},"execution_count":332,"outputs":[{"output_type":"stream","name":"stdin","text":"school Bethel\n"},{"name":"stdout","text":"Bethel (MN)\nBethel\nBethel (TN)\nBethel Col\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.read_html(\"http://www.dakstats.com/WebSync/Pages/Team/TeamSchedule.aspx?association=10&sg=MFB&sea=NAIMFB_2013&team=2206\")[16]","metadata":{"execution":{"iopub.status.busy":"2024-03-09T03:12:37.051009Z","iopub.execute_input":"2024-03-09T03:12:37.052281Z","iopub.status.idle":"2024-03-09T03:12:38.318450Z","shell.execute_reply.started":"2024-03-09T03:12:37.052228Z","shell.execute_reply":"2024-03-09T03:12:38.317112Z"},"trusted":true},"execution_count":328,"outputs":[{"execution_count":328,"output_type":"execute_result","data":{"text/plain":"     0\n0  WVB","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WVB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"naiadf=pd.DataFrame(arr,columns=['Team','Wins','Losses','Season'])\nnaiadf.to_csv(\"d3footballstandings.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T01:45:25.491519Z","iopub.execute_input":"2024-01-03T01:45:25.491884Z","iopub.status.idle":"2024-01-03T01:45:25.511749Z","shell.execute_reply.started":"2024-01-03T01:45:25.491855Z","shell.execute_reply":"2024-01-03T01:45:25.510579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naiadf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d3footballstandings.csv\")\ny=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/d3footballteams.json\")\ny=y.json()\nnaiadf['Team']=naiadf.Team.str.replace(\"/0 \",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"UPI \",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"AP / No. \",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"/NR\",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"†\",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"3\",\"\")\nnaiadf['Team']=naiadf.Team.str.replace(\"–\",\"-\")\nnaiadf['Team']=naiadf.Team.str.strip()\nnaiadf['Team']=naiadf['Team'].astype(\"str\")\nfor team in y:\n    naiadf['Team']=naiadf['Team'].replace(team,y[team])\nfor team in set(naiadf.Team.tolist()):\n    if team not in eloLeaguez.ratingDict.keys():\n        print(team)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T02:22:09.738577Z","iopub.execute_input":"2024-01-03T02:22:09.738972Z","iopub.status.idle":"2024-01-03T02:22:10.318948Z","shell.execute_reply.started":"2024-01-03T02:22:09.738940Z","shell.execute_reply":"2024-01-03T02:22:10.317277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naiadf.to_csv(\"naia1969-1994.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:24:08.192362Z","iopub.execute_input":"2023-12-28T22:24:08.192870Z","iopub.status.idle":"2023-12-28T22:24:08.204561Z","shell.execute_reply.started":"2023-12-28T22:24:08.192829Z","shell.execute_reply":"2023-12-28T22:24:08.202868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naiadf.to_csv(\"naiastandings1969-1994.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:45:37.338323Z","iopub.execute_input":"2023-12-28T22:45:37.338848Z","iopub.status.idle":"2023-12-28T22:45:37.370243Z","shell.execute_reply.started":"2023-12-28T22:45:37.338812Z","shell.execute_reply":"2023-12-28T22:45:37.368486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j=1\nfor i in range(1978,2024):\n    u=[]\n    for key in teamzzz[i]:\n        \n        if key not in eloLeaguez.ratingDict.keys():\n            if 'standings' not in str(key) and \"Poll\" not in str(key) and 'football' not in str(key):\n                \n                key=key.replace(\"  \",\"\")\n                u.append(key)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.120381Z","iopub.status.idle":"2023-12-27T16:16:17.120773Z","shell.execute_reply.started":"2023-12-27T16:16:17.120579Z","shell.execute_reply":"2023-12-27T16:16:17.120598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"currentweek=from20000[from20000['date'].str.contains('2024-01-09')]\nfor row in currentweek.itertuples():\n    hpen=0\n    game=row\n    apen=0\n    if game.away not in str(fbsteams[game.season]) and game.away not in str(teamzzz[game.season]) and game.home in str(teamzzz[game.season]):\n        apen=fcsv\n    if game.home not in str(fbsteams[game.season]) and game.home not in str(teamzzz[game.season]) and game.away in str(teamzzz[game.season]):\n        hpen=fcsv\n    if row.home in str(fbsteams[row.season]) and row.away in str(teamzzz[row.season]):\n        apen=fcs\n    if row.away in str(fbsteams[row.season]) and row.home in str(teamzzz[row.season]):\n        hpen=fcs\n    if row.neutral==True:\n        helo=eloLeaguez.ratingDict[row.home]-hpen\n    else:\n        helo=eloLeaguez.ratingDict[row.home]+100-hpen\n    aelo=eloLeaguez.ratingDict[row.away]-apen\n    \n    if aelo>helo:\n        \n        spread=aelo-helo\n        spread=spread/20\n        spread=round(spread)\n        if spread==0:\n            spread=1\n        print(row.away+\" \"+\"beats \"+\" \"+row.home+\" \"+ \"by \"+str(spread)+\" <br/>\")\n    if helo>aelo or helo==aelo:\n        spread=helo-aelo\n        spread=spread/20\n        spread=round(spread)\n        if spread==0:\n            spread=1\n        print(row.home+\" \"+\"beats \"+\" \"+row.away+\" \"+ \"by \"+str(spread)+\" <br/>\")\n    \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-08T23:20:57.507732Z","iopub.execute_input":"2024-01-08T23:20:57.508175Z","iopub.status.idle":"2024-01-08T23:20:57.597710Z","shell.execute_reply.started":"2024-01-08T23:20:57.508143Z","shell.execute_reply":"2024-01-08T23:20:57.596629Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Michigan beats  Washington by 12 <br/>\n","output_type":"stream"}]},{"cell_type":"code","source":"tp=0\nn={}\nn['f']=0\nn['t']=0\nfor row in fcs.itertuples():\n    tp+=(row.homep+row.awayp)\n    if 'True' in str(row.neutral):\n        n['t']+=1\n    else:\n        n['f']+=1\n    \ntp","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.137352Z","iopub.status.idle":"2023-12-27T16:16:17.138095Z","shell.execute_reply.started":"2023-12-27T16:16:17.137844Z","shell.execute_reply":"2023-12-27T16:16:17.137873Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d31995-2022.csv\")\ndf1['Schl']=df1['Schl'].str.replace(\"_\",\" \")\ndf1['Opp']=df1['Opp'].str.replace(\"_\",\" \")\n    \nh=[]\nfor team in set(df1.Schl.tolist()+df1.Opp.tolist()):\n    if team not in eloLeaguez.ratingDict.keys():\n        print(team)\n        h.append(team)\nprint(len(h))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.143911Z","iopub.status.idle":"2023-12-27T16:16:17.144327Z","shell.execute_reply.started":"2023-12-27T16:16:17.144128Z","shell.execute_reply":"2023-12-27T16:16:17.144148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=input(\"school\")\nfor key in eloLeaguez.ratingDict.keys():\n    if s in key:\n        print(key)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T21:43:13.815539Z","iopub.execute_input":"2024-01-02T21:43:13.815893Z","iopub.status.idle":"2024-01-02T21:43:15.427817Z","shell.execute_reply.started":"2024-01-02T21:43:13.815863Z","shell.execute_reply":"2024-01-02T21:43:15.426264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from2000[from2000.home=='Virginia State']","metadata":{"execution":{"iopub.status.busy":"2024-01-02T21:48:09.424115Z","iopub.execute_input":"2024-01-02T21:48:09.424797Z","iopub.status.idle":"2024-01-02T21:48:09.463771Z","shell.execute_reply.started":"2024-01-02T21:48:09.424755Z","shell.execute_reply":"2024-01-02T21:48:09.461810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1=input(\"t1\")\nt2=input(\"t2\")\n\nf=input(\"fcs\")\nh=200\nif str(1) in f:\n    ap=200\nelse:\n    ap=0\nt1e=eloLeaguez.ratingDict[t1]+h\nt2e=eloLeaguez.ratingDict[t2]-ap\nprint(t1+\" by \"+str((t1e-t2e)/20))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:19:06.867010Z","iopub.execute_input":"2023-12-29T15:19:06.867515Z","iopub.status.idle":"2023-12-29T15:19:19.064834Z","shell.execute_reply.started":"2023-12-29T15:19:06.867465Z","shell.execute_reply":"2023-12-29T15:19:19.063670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:51:42.663206Z","iopub.execute_input":"2023-12-27T23:51:42.663618Z","iopub.status.idle":"2023-12-27T23:51:42.685711Z","shell.execute_reply.started":"2023-12-27T23:51:42.663583Z","shell.execute_reply":"2023-12-27T23:51:42.684427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gz=[]\nnjcaaurlss={\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12814&all=1&mode=3&format=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12814&all=1&mode=3&format=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=12814&all=1&mode=3&format=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=12814&all=1&mode=3&format=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=12814&all=1&mode=3&format=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=12814&all=1&mode=3&format=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=12814&all=1&mode=3&format=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=12814&all=1&mode=3&format=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=12814&all=1&mode=3&format=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=12814&all=1&mode=3&format=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=12814&all=1&mode=3&format=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=12814&all=1&mode=3&format=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=12814&all=1&mode=3&format=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=12814&all=1&mode=3&format=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=12814&all=1&mode=3&format=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=12814&all=1&mode=3&format=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=12814&all=1&mode=3&format=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12814&all=1&mode=3&format=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12814&all=1&mode=3&format=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12814&all=1&mode=3&format=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12814&all=1&mode=3&format=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=12814&all=1&mode=3&format=1\"}\nnjcaaurls={\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12799&all=1&mode=3&format=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12799&all=1&mode=3&format=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12799&all=1&mode=3&format=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12799&all=1&mode=3&format=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12799&all=1&mode=3&format=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12799&all=1&mode=3&format=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12799&all=1&mode=3&format=1\"}\nfor key in njcaaurls:\n    gg=[]\n    r = requests.get(njcaaurls[key])\n    soup = bs(r.content, 'lxml')\n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(bs(r.content, 'lxml'))\n    q=aa\n    q=q.split(\"\\n\")\n    for line in q:\n        \n        \n        \n        \n        line=str(line)\n        \n        \n        \n        line = list(line.split(', '))\n        if \"<\" not in str(line):\n            \n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(key)]\n            gg.append(row)\n        if \"<p>\" in str(line):\n            line=str(line)\n            line=line.split(\"<p>\")\n            line=line[1]\n            line=list(line.split(', '))\n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(key)]\n            gg.append(row)\n    d22=pd.DataFrame(gg,columns=['Date','Schl','venue1','PTS','Opp','venue2','OPP','Year'])\n    \n    nof=njcaaurls[key]\n    nof=str(nof)\n    nof=nof.split(\"&format=\")\n    nof=nof[0]\n    nof=nof+\"&format=2\"\n    htmlz=requests.get(nof).text\n    soupz=BeautifulSoup(htmlz)\n    tds={}\n    d22.reset_index(inplace=True)\n    d22 = d22.astype({\"Schl\": str, \"Opp\": str})\n    d22=d22.astype(\"string\")\n    d22['Schl']=d22['Schl'].str.replace(\"'\",\"\")\n    d22['Opp']=d22['Opp'].str.replace(\"'\",\"\")\n    d22['PTS']=d22['PTS'].str.replace(\"'\",\"\")\n    d22['OPP']=d22['OPP'].str.replace(\"'\",\"\")\n    d22['venue1']=d22['venue1'].str.replace(\"'\",\"\")\n    d22['venue2']=d22['venue2'].str.replace(\"'\",\"\")\n    for line in soupz.text.split('\\n')[:-1]:\n        k=str(line)\n        k=k.replace(\" \",\"\")\n        k=k.split(\",\")\n  \n        tds[float(k[0])]=k[1]\n    for row in d22.itertuples():\n        schl=str(row.Schl)\n        schl=schl.replace(\" \",\"\")\n        schl=float(schl)\n        d22.at[row.Index,\"Schl\"]=tds[schl]\n        o=str(row.Opp)\n        o=o.replace(\" \",\"\")\n        o=float(o)\n        d22.at[row.Index,\"Opp\"]=tds[o]\n    for row in d22.itertuples():\n        ap=str(row.OPP)\n        ap=ap.replace(\"]\",\"\")\n        gz.append([row.Date,row.Schl,row.venue1,row.PTS,row.Opp,row.venue2,float(ap),row.Year])\n    print(key)\nd22=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd22=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd22.reset_index(inplace=True)\nd22=d22.astype('string')\n\nd22['venue1']=d22['venue1'].replace(\" 0\",\"vs\")\nd22['venue2']=d22['venue2'].replace(\" 0\",\"True\")\nd22['venue1']=d22['venue1'].replace(\" 1\",\"vs\")\nd22['venue1']=d22['venue1'].replace(\"-1\",\"@\")\nd22=d22.rename(columns={'venue2':'neutral','venue1':'Venue'})\nd22=d22.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','Venue':'venue1'})\nd22['neutral']=d22['neutral'].str.replace(\"-1\",'False')\nd22['neutral']=d22['neutral'].str.replace(\"1\",'False')\nd22['neutral']=d22['neutral'].str.replace(\"0\",'True')","metadata":{"execution":{"iopub.status.busy":"2023-12-28T00:25:21.915533Z","iopub.execute_input":"2023-12-28T00:25:21.915990Z","iopub.status.idle":"2023-12-28T00:25:30.705790Z","shell.execute_reply.started":"2023-12-28T00:25:21.915952Z","shell.execute_reply":"2023-12-28T00:25:30.704350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=input(\"school\")\nfor key in eloLeaguez.ratingDict.keys():\n    if s in key:\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:20:01.765089Z","iopub.execute_input":"2023-12-28T22:20:01.766542Z","iopub.status.idle":"2023-12-28T22:20:04.208053Z","shell.execute_reply.started":"2023-12-28T22:20:01.766493Z","shell.execute_reply":"2023-12-28T22:20:04.206496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in set(d22.home.tolist()+d22.away.tolist()):\n    if key not in eloLeaguez.ratingDict.keys():\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:34:40.443944Z","iopub.execute_input":"2023-12-28T13:34:40.445187Z","iopub.status.idle":"2023-12-28T13:34:40.453337Z","shell.execute_reply.started":"2023-12-28T13:34:40.445142Z","shell.execute_reply":"2023-12-28T13:34:40.452049Z"},"trusted":true},"execution_count":null,"outputs":[]}]}