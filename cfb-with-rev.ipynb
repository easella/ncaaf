{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":189706,"sourceType":"datasetVersion","datasetId":81687}],"dockerImageVersionId":30357,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"msqe with 23:291.48765266821823\nmsqe with 22:290.261147611888\nmsqe with 21:290.1394455543427\nmsqe with 20:291.39622680369905","metadata":{}},{"cell_type":"code","source":"!pip install cfbd","metadata":{"execution":{"iopub.status.busy":"2023-12-28T21:20:13.390347Z","iopub.execute_input":"2023-12-28T21:20:13.390849Z","iopub.status.idle":"2023-12-28T21:20:30.829894Z","shell.execute_reply.started":"2023-12-28T21:20:13.390753Z","shell.execute_reply":"2023-12-28T21:20:30.828091Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting cfbd\n  Downloading cfbd-4.5.2-py3-none-any.whl (358 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.8/358.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from cfbd) (2022.12.7)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from cfbd) (2.8.2)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from cfbd) (1.15.0)\nRequirement already satisfied: urllib3>=1.23 in /opt/conda/lib/python3.7/site-packages (from cfbd) (1.26.13)\nInstalling collected packages: cfbd\nSuccessfully installed cfbd-4.5.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"fcs=fcs[fcs.home!='Knoxville']\nfcs=fcs[fcs.away!='Knoxville']","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.081104Z","iopub.execute_input":"2023-12-27T16:16:17.081453Z","iopub.status.idle":"2023-12-27T16:16:17.108447Z","shell.execute_reply.started":"2023-12-27T16:16:17.081419Z","shell.execute_reply":"2023-12-27T16:16:17.105862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dgz=list(set(file.home.tolist()+file.away.tolist()))+list(set(dfz.home.tolist()+dfz.away.tolist()))\ndef Convert(lst):\n    res_dct = {lst[i]: 0 for i in range(0, len(lst), 2)}\n    return res_dct\ndg=Convert(dgz)\nh=[]\nfor k in sorted(dg):\n    \n    h.append(k)\nfilez=open(\"keys.txt\",\"w\")\nfilez.write(str(h))  \nfilez.close()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.110207Z","iopub.status.idle":"2023-12-27T16:16:17.110901Z","shell.execute_reply.started":"2023-12-27T16:16:17.110679Z","shell.execute_reply":"2023-12-27T16:16:17.110703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install cfbd","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.112232Z","iopub.status.idle":"2023-12-27T16:16:17.112887Z","shell.execute_reply.started":"2023-12-27T16:16:17.112675Z","shell.execute_reply":"2023-12-27T16:16:17.112696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport math\nfrom datetime import date,datetime,timedelta\ncan=1\nimport os\nimport pandas as pd\n\nkey=\"LX8oTIQmXarLqV7XwEcEbhkgN6ubBp0yQkA5arybroBCPul3UhonRiw0iN4eWPpK\"\ndfz=pd.read_csv(\"https://ontheroadtovote.com/ncaab/ncaaf.csv\")\nimport cfbd\nimport numpy as np\n# configure API key\nconfiguration = cfbd.Configuration()\nconfiguration.api_key['Authorization'] =key\nconfiguration.api_key_prefix['Authorization'] = 'Bearer'\n# instantiate a games API instance\napi_config = cfbd.ApiClient(configuration)\ngames_api = cfbd.GamesApi(cfbd.ApiClient(configuration))\ndf=dfz[dfz.season>2024]\nz=[]\ngamesz =[]\ngames=[]\nresponse = games_api.get_games(year=2022,season_type = 'both')\ngamess = [*games, *response]\nt=[]\nz=[]\ndef s(g):\n    a=dict(home=g.home_team,homeconf=g.home_conference,homep=g.home_points,away=g.away_team,awayconf=g.away_conference,awayp=g.away_points,attendance=g.attendance,neutral=g.neutral_site,season=g.season,playoff=0,date=g.start_date,week=g.week,id=g.id,season_type=g.season_type)\n    z.append(a)\nlist(map(s,gamess))\nresponse = games_api.get_games(year=2023,season_type = 'both')\ngamess = [*games, *response]\ndef s(g):\n    a=dict(home=g.home_team,homeconf=g.home_conference,homep=g.home_points,away=g.away_team,awayconf=g.away_conference,awayp=g.away_points,attendance=g.attendance,neutral=g.neutral_site,season=g.season,playoff=0,date=g.start_date,week=g.week,id=g.id,season_type=g.season_type)\n    z.append(a)\nlist(map(s,gamess))\nmsqe=[]\nlh=0\nwh=0\nn=0\nfrom2000  = pd.DataFrame(z)\nfrom2000=from2000.fillna(0)\nfrom2000=from2000[(from2000.season_type=='regular')|(from2000.season_type=='postseason')]\nfrom2000=from2000\ndf=from2000\nfrom20000=from2000\nfrom2000=from2000[(from2000.homep>0)|(from2000.awayp>0)]\nfrom2000=from2000.sort_values(by='date')\nfrom decimal import Decimal\nimport decimal\ndecimal.getcontext().prec = 100\ndecimal.getcontext().Emax=1000000000\ndecimal.getcontext().Emin=-1000000000\nhfan=95\neloz={}\neloz['n']=0\neloz['wh']=0\neloz['lh']=0\nclass Elo:\n  def __init__(self,k,g=1,homefield = 100):\n    wh=0\n    lh=0\n    n=0\n    self.ratingDict   = {}  \n    self.k        = k\n    self.g        = g\n  def addPlayer(self,name,rating = 1500):\n    self.ratingDict[name] = rating\n  def gameOver(self, winner, loser, winnerHome,neutral,wins,loses,wpen,lpen):\n    if 'True' in str(neutral):\n        homef=0\n    else:\n        \n        homef=100\n    if winnerHome==True:\n      eloz['wh']+=1\n      result = self.expectResult(self.ratingDict[winner]-wpen + homef, self.ratingDict[loser]-lpen)\n    if winnerHome==0:\n      eloz['lh']+=1\n      result = self.expectResult(self.ratingDict[winner]-wpen, self.ratingDict[loser]-lpen + homef)\n    else:\n        \n        result = self.expectResult(self.ratingDict[winner]-wpen, self.ratingDict[loser]-lpen)\n\n                    \n    wins=float(wins)\n    loses=float(loses)\n    result=float(result)\n    isneutral='True'  in str(neutral) or '0' in str(neutral)\n    if wins==loses:\n        mult=(math.log(0+1))*(2.2/1*0.001+2.2)\n        shift=(self.k*mult)*(0.5 - result)  \n        self.ratingDict[winner] +=shift\n        self.ratingDict[loser]  -=shift\n    if wins!=loses:\n        win=eloLeaguez.ratingDict[winner]-wpen\n        lose=eloLeaguez.ratingDict[loser]-lpen\n        if isneutral:\n          win=(eloLeaguez.ratingDict[winner]-wpen)\n          lose=(eloLeaguez.ratingDict[loser]-lpen)\n        if winnerHome and isneutral==False:\n          win=(100+eloLeaguez.ratingDict[winner]-wpen)\n          lose=(eloLeaguez.ratingDict[loser]-lpen)\n        if winnerHome!=True and 'True' not in str(neutral) and '0' not in str(neutral):\n          lose=(100+eloLeaguez.ratingDict[loser]-lpen)\n          win=(eloLeaguez.ratingDict[winner]-wpen)\n        global zy\n        if(win>lose):\n          zy=(win-lose)\n        if(win==lose):\n          zy=(win-lose)+0.00001\n        if(win<lose):\n          zy=(win-lose)\n        mult=(math.log((abs(wins-loses))+1))*(2.2/(zy)*0.001+2.2)\n        shift=(self.k*float(mult))*(1 - result)  \n        self.ratingDict[winner] +=shift\n        self.ratingDict[loser]  -=shift\n  from math import pow\n  def expectResult(self, p1, p2):\n    p2=Decimal(p2)\n    p1=Decimal(p1)\n    exp = Decimal((p2-p1))/Decimal(400.0)\n    b=float(Decimal(Decimal(1)/((pow(Decimal(10.0),Decimal(exp)))+Decimal(1))))\n    az['h']=str(b)\n    return float(Decimal(Decimal(1)/((pow(Decimal(10.0),Decimal(exp)))+Decimal(1))))\nteamss={}\naz={}\naz['h']='hello'\ntoday = date.today()\nallTeams  = set(dfz.away.tolist()+dfz.home.tolist())\nallTeamsh  = set(dfz.home.tolist())\nglobal st\neloLeaguez= Elo(k = 20,homefield=100)\ndfz=dfz[(dfz.season_type=='postseason')|(dfz.season_type=='regular')]\nfrom2000['homeconf'].fillna(0,inplace=True)\nfrom2000['awayconf'].fillna(0,inplace=True)\ndf7=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d31995-2022.csv\",skipinitialspace = True)\nimport re\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom bs4 import BeautifulSoup as bs\ntds={}\n\ngz=[]\ntoday=date.today()\n#scrape naia scores from the 2023 season\nif 1==1:\n    d3urls={\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12795&all=1&mode=3&format=1\"}\nelse:\n    d3urls={}\nfor key in d3urls:\n    gg=[]\n    r = requests.get(d3urls[key])\n    soup = bs(r.content, 'lxml')\n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(bs(r.content, 'lxml'))\n    q=aa\n    q=q.split(\"\\n\")\n    for line in q:\n        \n        \n        \n        \n        line=str(line)\n        \n        \n        \n        line = list(line.split(', '))\n        if \"<\" not in str(line):\n            \n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(2023)]\n            gg.append(row)\n        if \"<p>\" in str(line):\n            line=str(line)\n            line=line.split(\"<p>\")\n            line=line[1]\n            line=list(line.split(', '))\n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(2023)]\n            gg.append(row)\n    d22=pd.DataFrame(gg,columns=['Date','Schl','venue1','PTS','Opp','venue2','OPP','Year'])\n    \n    nof=d3urls[key]\n    nof=str(nof)\n    nof=nof.split(\"&format=\")\n    nof=nof[0]\n    nof=nof+\"&format=2\"\n    htmlz=requests.get(nof).text\n    soupz=BeautifulSoup(htmlz)\n    tds={}\n    d22.reset_index(inplace=True)\n    d22 = d22.astype({\"Schl\": str, \"Opp\": str})\n    d22=d22.astype(\"string\")\n    d22['Schl']=d22['Schl'].str.replace(\"'\",\"\")\n    d22['Opp']=d22['Opp'].str.replace(\"'\",\"\")\n    d22['PTS']=d22['PTS'].str.replace(\"'\",\"\")\n    d22['OPP']=d22['OPP'].str.replace(\"'\",\"\")\n    d22['venue1']=d22['venue1'].str.replace(\"'\",\"\")\n    d22['venue2']=d22['venue2'].str.replace(\"'\",\"\")\n    for line in soupz.text.split('\\n')[:-1]:\n        k=str(line)\n        k=k.replace(\" \",\"\")\n        k=k.split(\",\")\n  \n        tds[float(k[0])]=k[1]\n    for row in d22.itertuples():\n        schl=str(row.Schl)\n        schl=schl.replace(\" \",\"\")\n        schl=float(schl)\n        d22.at[row.Index,\"Schl\"]=tds[schl]\n        o=str(row.Opp)\n        o=o.replace(\" \",\"\")\n        o=float(o)\n        d22.at[row.Index,\"Opp\"]=tds[o]\n    for row in d22.itertuples():\n        ap=str(row.OPP)\n        ap=ap.replace(\"]\",\"\")\n        gz.append([row.Date,row.Schl,row.venue1,row.PTS,row.Opp,row.venue2,float(ap),row.Year])\n    print(key)\nd22=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd22.reset_index(inplace=True)\nd22=d22.astype('string')\n\nd22['venue1']=d22['venue1'].replace(\" 0\",\"vs\")\nd22['venue2']=d22['venue2'].replace(\" 0\",\"True\")\nd22['venue1']=d22['venue1'].replace(\" 1\",\"vs\")\nd22['venue1']=d22['venue1'].replace(\"-1\",\"@\")\nd22=d22.rename(columns={'venue2':'neutral','venue1':'Venue'})\nd22=d22.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','Venue':'venue1'})\nd22['neutral']=d22['neutral'].str.replace(\"-1\",'False')\nd22['neutral']=d22['neutral'].str.replace(\"1\",'False')\nd22['neutral']=d22['neutral'].str.replace(\"0\",'True')\nr = requests.get('https://ontheroadtovote.com/ncaaf/fcs/teams.json')\ny=r.json()\n\nfor team in y:\n    d22=d22.replace(team,y[team])\nd22=d22.astype({\"date\":\"string\"})\nd22['date'] = pd.to_datetime(d22['date'], errors='coerce',utc=True)\nd22['date'] = d22['date'].dt.strftime('%Y-%m-%d')\ndf7=df7.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','Venue':'venue1'})\ndf7['neutral']=df7['neutral'].str.replace(\"-1\",'False')\ndf7['neutral']=df7['neutral'].str.replace(\"1\",'False')\ndf7['neutral']=df7['neutral'].str.replace(\"0\",'True')\ndf3=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/fcs1995-2002.csv\",skipinitialspace = True)\n\ndf3=df3.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','venue2':'neutral'})\ndf4=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/naia1995-2022.csv\",skipinitialspace = True)\n\ndf4=df4.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date'})\ndf4=df4.astype({\"date\":\"string\"})\ndf4['date'] = pd.to_datetime(df4['date'], errors='coerce',utc=True)\ndf4['date'] = df4['date'].dt.strftime('%Y-%m-%d')\ndf2=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d2d32002-2022.csv\",skipinitialspace = True)\ndf2=df2.rename(columns={'ht':'home','at':'away','Year':'season','Date':'date','PTS':'homep','OPP':'awayp'})\ndf1=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d21995-2022.csv\")\ndf5=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d22003-2022.csv\")\ndf5=df5.rename(columns={\"Schl\":\"home\",\"Opp\":\"away\",'Venue':\"venue1\",\"PTS\":'homep','OPP':\"awayp\",'Year':\"season\",'Date':\"date\"})\ndf1=df1.rename(columns={\"Schl\":\"home\",\"Opp\":\"away\",'Venue':\"venue1\",\"PTS\":'homep','OPP':\"awayp\",'Year':\"season\",'Date':\"date\"})\ndf6=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/naia1995-2022.csv\")\ndf6=df6.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','venue2':'neutral'})\ndf6=df6.astype(\"string\")\ndf6['home']=df6['home'].str.replace(\"_\",\" \")\ndf6['away']=df6['away'].str.replace(\"_\",\" \")\ndf6['home']=df6['home'].str.replace(\"Chr\",\"Christian\")\ndf6['away']=df6['away'].str.replace(\"Chr\",\"Christian\")\ndf6['home']=df6['home'].str.replace(\" St\",\" State\")\ndf6['away']=df6['away'].str.replace(\" St\",\" State\")\ngz=[]\n#scape njccaa scores from the 2023 season\nnjcaaurls={\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12814&all=1&mode=3&format=1\"}\nfor key in njcaaurls:\n    gg=[]\n    r = requests.get(njcaaurls[key])\n    soup = bs(r.content, 'lxml')\n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(bs(r.content, 'lxml'))\n    q=aa\n    q=q.split(\"\\n\")\n    for line in q:\n        \n        \n        \n        \n        line=str(line)\n        \n        \n        \n        line = list(line.split(', '))\n        if \"<\" not in str(line):\n            \n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(key)]\n            gg.append(row)\n        if \"<p>\" in str(line):\n            line=str(line)\n            line=line.split(\"<p>\")\n            line=line[1]\n            line=list(line.split(', '))\n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(key)]\n            gg.append(row)\n    d222=pd.DataFrame(gg,columns=['Date','Schl','venue1','PTS','Opp','venue2','OPP','Year'])\n    \n    nof=njcaaurls[key]\n    nof=str(nof)\n    nof=nof.split(\"&format=\")\n    nof=nof[0]\n    nof=nof+\"&format=2\"\n    htmlz=requests.get(nof).text\n    soupz=BeautifulSoup(htmlz)\n    tds={}\n    d222.reset_index(inplace=True)\n    d222 = d222.astype({\"Schl\": str, \"Opp\": str})\n    d222=d222.astype(\"string\")\n    d222['Schl']=d222['Schl'].str.replace(\"'\",\"\")\n    d222['Opp']=d222['Opp'].str.replace(\"'\",\"\")\n    d222['PTS']=d222['PTS'].str.replace(\"'\",\"\")\n    d222['OPP']=d222['OPP'].str.replace(\"'\",\"\")\n    d222['venue1']=d222['venue1'].str.replace(\"'\",\"\")\n    d222['venue2']=d222['venue2'].str.replace(\"'\",\"\")\n    for line in soupz.text.split('\\n')[:-1]:\n        k=str(line)\n        k=k.replace(\" \",\"\")\n        k=k.split(\",\")\n  \n        tds[float(k[0])]=k[1]\n    for row in d222.itertuples():\n        schl=str(row.Schl)\n        schl=schl.replace(\" \",\"\")\n        schl=float(schl)\n        d222.at[row.Index,\"Schl\"]=tds[schl]\n        o=str(row.Opp)\n        o=o.replace(\" \",\"\")\n        o=float(o)\n        d222.at[row.Index,\"Opp\"]=tds[o]\n    for row in d222.itertuples():\n        ap=str(row.OPP)\n        ap=ap.replace(\"]\",\"\")\n        gz.append([row.Date,row.Schl,row.venue1,row.PTS,row.Opp,row.venue2,float(ap),row.Year])\n    print(key)\nd222=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd222=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd222.reset_index(inplace=True)\nd222=d222.astype('string')\n\nd222['venue1']=d222['venue1'].replace(\" 0\",\"vs\")\nd222['venue2']=d222['venue2'].replace(\" 0\",\"True\")\nd222['venue1']=d222['venue1'].replace(\" 1\",\"vs\")\nd222['venue1']=d222['venue1'].replace(\"-1\",\"@\")\nd222=d222.rename(columns={'venue2':'neutral','venue1':'Venue'})\nd222=d222.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','Venue':'venue1'})\nd222['neutral']=d222['neutral'].str.replace(\"-1\",'False')\nd222['neutral']=d222['neutral'].str.replace(\"1\",'False')\nd222['neutral']=d222['neutral'].str.replace(\"0\",'True')\nd222['date']=d222.date.str.replace(\"'\",\"\")\nd222=d222.astype({\"date\":\"string\"})\nd222['date'] = pd.to_datetime(d222['date'], errors='coerce',utc=True)\nd222['date'] = d222['date'].dt.strftime('%Y-%m-%d')\nfor team in y:\n    d222=d222.replace(team,y[team])\nimport pandas as pd\nfbsteams={}\nfor i in range(1978,2024):\n    fbsteams[i]=[]\nfor i in range(1978,2024):\n    print(i)\n    if i<2006:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I-A_football_season\"\n    else:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I_FBS_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    tablez=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    for table in tablez:\n        links=table.find_all(\"a\")\n        for a in links:\n            if 'Team' in str(table):\n                a=str(a)\n                a=a.split(\">\")\n                a=a[1]\n                a=a.split(\"<\")\n                a=a[0]\n                if 'Miami (FL)' in str(a):\n                    a=a.replace(\"Miami (FL)\",\"Miami\")\n                fbsteams[i].append(a)\narrz=[]\nfor i in range(1978,2024):\n    ts=fbsteams[i]\n    for team in ts:\n        arrz.append([team,i])\nstandingstable=pd.concat([pd.DataFrame(arrz)])\nstandingstable.columns=['Team','Season']\nimport requests\nimport json\n\nteamstor={'Miami (FL)':'Miami','North Carolina A&amp;T':\"North Carolina A&T\",\"Grambling State\":\"Grambling\",\"North Texas State\":\"North Texas\",\"Northeast Louisiana\":\"Louisiana Monroe\",\"UCF\":\"Central Florida\",\"Texas-Arlington\":\"Texas Arlington\",\"Florida A&amp;M\":\"Florida A&M\",\"SW Texas State\":\"Texas State\",\"NE Louisiana\":\"Louisiana Monroe\",\"William &amp; Mary\":\"William & Mary\",\"Southwest Texas State\":\"Texas State\",\"Troy State\":\"Troy\",\"Texas–Arlington\":\"Texas Arlington\"}\nfor team in teamstor:\n    standingstable=standingstable.replace(team,teamstor[team])\nr = requests.get('https://ontheroadtovote.com/ncaaf/fbsteams.json')\ny=r.json()\n\nfor team in y:\n    standingstable=standingstable.replace(team,y[team])\nstandingstable=standingstable[standingstable.Team!='New Mexico State']\nstandingstable=standingstable[standingstable.Team!='Tulsa']\nstandingstable=standingstable[standingstable.Team!='Wichita State']\nteams={}\nfor i in range(1978,2024):\n    teams[i]=[]\nfor row in standingstable.itertuples():\n    teams[float(row.Season)].append(str(row.Team))\nfbsteams=teams\nteams={}\nfor i in range(1978,2024):\n    teams[i]=[]\nfor i in range(1978,2024):\n    print(i)\n    if i<2006:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I-AA_football_season\"\n    else:\n        url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NCAA_Division_I_FCS_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    tablez=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    for table in tablez:\n        links=table.find_all(\"a\")\n        for a in links:\n            if 'Team' in str(table):\n                a=str(a)\n                a=a.split(\">\")\n                a=a[1]\n                a=a.split(\"<\")\n                a=a[0]\n                if 'Bethune–Cookman' in str(a):\n                    a=a.replace(\"Bethune–Cookman\",\"Bethune-Cookman\")\n                if 'Alabama A&' in str(a):\n                    a=a.replace(\"Alabama A&amp;\",\"Alabama A&M\")\n                teams[i].append(a)\narrz=[]\n\nfor i in range(1978,2024):\n    ts=teams[i]\n    for team in ts:\n        arrz.append([team,i])\nstandingstable=pd.concat([pd.DataFrame(arrz)])\nstandingstable.columns=['Team','Season']\nteamstor={'Alabama A&amp;':'Alabama A&M','North Carolina A&amp;T':\"North Carolina A&T\",\"Grambling State\":\"Grambling\",\"North Texas State\":\"North Texas\",\"Northeast Louisiana\":\"Louisiana Monroe\",\"UCF\":\"Central Florida\",\"Texas-Arlington\":\"Texas Arlington\",\"Florida A&amp;M\":\"Florida A&M\",\"SW Texas State\":\"Texas State\",\"NE Louisiana\":\"Louisiana Monroe\",\"William &amp; Mary\":\"William & Mary\",\"Southwest Texas State\":\"Texas State\",\"Troy State\":\"Troy\",\"Texas–Arlington\":\"Texas Arlington\",\"Prairie View A&amp;M\":\"Prairie View\",\"West Texas State\":\"West Texas A&M\"}\nfor team in teamstor:\n    standingstable=standingstable.replace(team,teamstor[team])\nfor team in y:\n    standingstable=standingstable.replace(team,y[team])\nstandingstable=standingstable[standingstable.Team!='New Mexico State']\nstandingstable=standingstable[standingstable.Team!='Tulsa']\nstandingstable=standingstable[standingstable.Team!='Wichita State']\nteams={}\nfor i in range(1978,2024):\n    teams[i]=[]\nfor row in standingstable.itertuples():\n    teams[float(row.Season)].append(str(row.Team))\nteamzzz=teams\nteamzzz=teams\nfrom bs4 import BeautifulSoup\nimport requests\nhtml=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/index.php\")\nsoup=BeautifulSoup(html.text)\nlinks=soup.find_all(\"a\")\narr=[]\ny=0\npts={}\narrz=[]\nns={}\n\nfor a in links:\n    y+=1\n    url='https://ontheroadtovote.com/ncaaf/fcs/'+a['href']\n    \n    if '.txt' in str(a) and 'teams' not in str(a):\n        df=pd.read_csv(url)\n        df=df.replace(\"Eastern Washngton\",\"Eastern Washington\")\n        df=df.replace(\"Nofrolk State\",'Norfolk State')\n        for row in df.itertuples():\n            if row.Schl not in pts:\n                pts[row.Schl]=0\n                \n            if 'Year' in str(row):\n                s=row.Year \n            if 'Season' in str(row):\n                s=row.Season\n            if 'season' in str(row):\n                s=row.season\n            if 'netural' in str(row):\n                n=row.netural\n            if 'neutral' in str(row):\n                n=row.neutral\n            schl=str(row.Schl)\n            opp=str(row.Opp)\n            didf=0\n            if 'for' in schl:\n                schl=schl.split(\"(\")\n                schl=schl[0]\n                if row.PTS==1 and row.OPP==0:\n                    didf=1\n                if row.PTS==0 and row.OPP==1:\n                    didf=1\n            if 'for' in opp:\n                opp=opp.split(\"(\")\n                opp=opp[0]\n                if row.PTS==1 and row.OPP==0:\n                    didf=1\n                if row.PTS==0 and row.OPP==1:\n                    didf=1\n            if float(s)<1995:\n                na=row.Opp+row.Schl+row.Date+str(row.OPP)+str(row.PTS)\n            \n                if na not in arrz:\n                    if row.Schl in teams[float(s)]:\n                        inarr=1\n                        if didf==0:\n                            arrz.append(row.Schl+row.Opp+row.Date+str(row.PTS)+str(row.OPP))\n                            arr.append([schl,opp,row.Venue,row.PTS,row.OPP,row.Date,s,n])\n                        \n        \ndf=pd.concat([pd.DataFrame(arr)])\ndf.columns=['Schl','Opp','Venue','PTS',\"OPP\",'date','Season','neutral']\ndf=df[df.Season<1995]\ndf.sort_values(by='date') \nfor row in df.itertuples():\n    if row.Opp not in pts:\n        pts[row.Opp]=0\n    pts[row.Schl]+=float(row.PTS)\n    pts[row.Opp]+=float(row.OPP)\n    g=str(row.Schl)\n    g=g.rstrip()\n        \n    gz=str(row.Opp)\n    gz=gz.rstrip()\n    df.at[row.Index,'Schl']=g\n    df.at[row.Index,'Opp']=gz\ndf=df.rename(columns={'Schl':'home','Opp':\"away\",\"PTS\":\"homep\",'OPP':'awayp','Season':'season','Venue':'venue1'})\nfcs=df\nfcs=fcs.replace(\"Nicholls State State\",\"Nicholls State\")\nfcs=fcs.replace(\"Middle Tennessee State State\",\"Middle Tennessee State\")\nfcs=fcs.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\nfcs['date']= pd.to_datetime(fcs['date'])\nprint(\"didfcs\")\nnjcaa=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/uscaafootball.csv\")\nnjcaa=njcaa.astype({\"date\":\"string\"})\nnjcaa['date'] = pd.to_datetime(njcaa['date'], errors='coerce',utc=True)\nnjcaa['date'] = njcaa['date'].dt.strftime('%Y-%m-%d')\nr = requests.get('https://ontheroadtovote.com/ncaaf/fbsteams.json')\ny=r.json()\nnccaa=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/nccaafootball.csv\")\nnccaa=nccaa.astype({\"away\":\"string\",\"home\":\"string\"})\nnccaa=nccaa.astype({\"date\":\"string\"})\nnccaa['date'] = pd.to_datetime(nccaa['date'], errors='coerce',utc=True)\nnccaa['date'] = nccaa['date'].dt.strftime('%Y-%m-%d')\nfor team in y:\n    njcaa=njcaa.replace(team,y[team])\n    nccaa=nccaa.replace(team,y[team])\n\nfile=pd.concat([df3,df5,df1,df6,fcs,df7,d22])\nteamsf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/teams.txt\")\nteamz={}\nfile=file.astype(\"string\")\nfile.reset_index(inplace=True)\nfile['home'].str.replace(' ', '')\nfile['away'].str.replace(' ', '')\nfile['home']=file['home'].replace(\"Charleston So \",\"Charleston Southern\")\nfile['home']=file['home'].str.rstrip()\nfile['away']=file['away'].str.rstrip()\nfile['away']=file['away'].replace(\"Charleston So \",\"Charleston Southern\")\nteamw={}\nteamw['Charleston So']='Charleston Southern'\ny=[]\nga=[]\nthiss=pd.DataFrame(z)\nthiss=thiss[thiss.season==2023]\nfor row in thiss.itertuples():\n    ga.append([row.home,row.away,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\nfor row in file.itertuples():\n    g=str(row.home)\n    g=g.rstrip()\n        \n    gz=str(row.away)\n    gz=gz.rstrip()\n    file.at[row.Index,'home']=g\n    file.at[row.Index,'away']=gz\nfor row in file.itertuples():\n    if row.home in teamw:\n        file.at[row.Index,'home']=teamw[row.home]\n    if row.away in teamw:\n        file.at[row.Index,'away']=teamw[row.away]\n    if row.home in teamz:\n        y.append(row.home)\n        file.at[row.Index,'home']=teamz[row.home]\n    if row.away in teamz:\n        y.append(row.away)\n        file.at[row.Index,'away']=teamz[row.away]\nfile['home'] = file.home.str.replace('_', ' ')\nfile['away'] = file.away.str.replace('_', ' ')\n\n\nfcsa=[]\ncss=2023\n\nfrom2000=from2000.replace(\"]\",\"\")\nfrom2000=from2000.replace(\"[\",\"\")\nfrom2000=from2000.astype({'season':float,'homep':float,'awayp':float})\nfrom2000=from2000.drop_duplicates()\nfrom2000.sort_values(by='date',inplace=True)\nfrom2000=from2000\n\nfrom2000['date'] = pd.to_datetime(from2000['date'], errors='coerce',utc=True)\n\nfrom2000['date'] = pd.to_datetime(from2000.date,utc=True)\nfrom2000['date'] = from2000['date'].dt.strftime('%Y-%m-%d')\ncurrd=from2000\ncurrteams=set(currd.home.tolist()+currd.away.tolist())\nallconfs={}\nprint('ready')\nimport requests\nw=0\nl=0\nregm=0\ndf=dfz\ncurrSeason=1869\nfrom20000=from2000\ny=0\ndobye=0\ndc=0\nrev=(0.30)\ntds={}\n\nimport requests\nhtml=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/teams.json\")\nhtml=html.json()\nhtmlz=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/d2d3teams.json\")\nhtmlz=htmlz.json()\nhtmlzz=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/d2d3teams.json\")\nhtmlzz=htmlzz.json()\neloLeaguez.addPlayer(\"Morris Brown\")\nfor row in d22.itertuples():\n    ht=row.home\n    date=row.date\n    at=row.away\n    if row.home in htmlz:\n        ht=htmlz[row.home]\n    if row.away in htmlz:\n        at=htmlz[row.away]\n    if row.home in htmlzz:\n        ht=htmlzz[row.home]\n    if row.away in htmlzz:\n        at=htmlzz[row.away]\n    if row.home in html:\n        ht=html[row.home]\n    if row.away in html:\n        at=html[row.away]\n    if '-1' in str(row.venue1):\n        venue='@'\n    if str(row.venue1)=='1' or '0' in str(row.venue1):\n        venue='vs'\n    if '1' and '0' not in str(row.venue1):\n        venue=row.venue1\n    ga.append([ht,at,row.neutral,row.season,date,row.homep,row.awayp,venue])\nfor row in d222.itertuples():\n    ht=row.home\n    date=row.date\n    at=row.away\n    if row.home in htmlz:\n        ht=htmlz[row.home]\n    if row.away in htmlz:\n        at=htmlz[row.away]\n    if row.home in htmlzz:\n        ht=htmlzz[row.home]\n    if row.away in htmlzz:\n        at=htmlzz[row.away]\n    if row.home in html:\n        ht=html[row.home]\n    if row.away in html:\n        at=html[row.away]\n    if '-1' in str(row.venue1):\n        venue='@'\n    if str(row.venue1)=='1' or '0' in str(row.venue1):\n        venue='vs'\n    if '1' and '0' not in str(row.venue1):\n        venue=row.venue1\n    ga.append([ht,at,row.neutral,row.season,date,row.homep,row.awayp,venue])\nfor row in njcaa.itertuples():\n    ht=row.home\n    date=row.date\n    at=row.away\n    if row.home in htmlz:\n        ht=htmlz[row.home]\n    if row.away in htmlz:\n        at=htmlz[row.away]\n    if row.home in htmlzz:\n        ht=htmlzz[row.home]\n    if row.away in htmlzz:\n        at=htmlzz[row.away]\n    if row.home in html:\n        ht=html[row.home]\n    if row.away in html:\n        at=html[row.away]\n    if '-1' in str(row.venue1):\n        venue='@'\n    if str(row.venue1)=='1' or '0' in str(row.venue1):\n        venue='vs'\n    if '1' and '0' not in str(row.venue1):\n        venue=row.venue1\n    ga.append([ht,at,row.neutral,row.season,date,row.homep,row.awayp,venue])\nfor row in nccaa.itertuples():\n    ht=row.home\n    date=row.date\n    at=row.away\n    if row.home in htmlz:\n        ht=htmlz[row.home]\n    if row.away in htmlz:\n        at=htmlz[row.away]\n    if row.home in htmlzz:\n        ht=htmlzz[row.home]\n    if row.away in htmlzz:\n        at=htmlzz[row.away]\n    if row.home in html:\n        ht=html[row.home]\n    if row.away in html:\n        at=html[row.away]\n    if '-1' in str(row.venue1):\n        venue='@'\n    if str(row.venue1)=='1' or '0' in str(row.venue1):\n        venue='vs'\n    if '1' and '0' not in str(row.venue1):\n        venue=row.venue1\n    ga.append([ht,at,row.neutral,row.season,date,row.homep,row.awayp,venue])\nfor row in file.itertuples():\n    ht=row.home\n    date=row.date\n    at=row.away\n    if row.home in htmlz:\n        ht=htmlz[row.home]\n    if row.away in htmlz:\n        at=htmlz[row.away]\n    if row.home in htmlzz:\n        ht=htmlzz[row.home]\n    if row.away in htmlzz:\n        at=htmlzz[row.away]\n    if row.home in html:\n        ht=html[row.home]\n    if row.away in html:\n        at=html[row.away]\n    if '-1' in str(row.venue1):\n        venue='@'\n    if str(row.venue1)=='1' or '0' in str(row.venue1):\n        venue='vs'\n    if '1' and '0' not in str(row.venue1):\n        venue=row.venue1\n    ga.append([ht,at,row.neutral,row.season,date,row.homep,row.awayp,venue])\nfor row in dfz.itertuples():\n    ht=row.home\n    at=row.away\n    if (row.date>str(\"1995-11-25\"))and float(row.homep)==0 and float(row.awayp)==0:\n        m=1\n    if (row.date<str(\"1995-11-26\"))and float(row.homep)==0 and float(row.awayp)==0:\n        ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\n    \n    if row.home in htmlz:\n        ht=htmlz[row.home]\n    if row.away in htmlz:\n        at=htmlz[row.away]\n    if row.home in html:\n        ht=html[row.home]\n    if row.away in html:\n        at=html[row.away]\n        \n    if ((float(row.homep)==0 and float(row.awayp)==0)==False):\n        if 'i' in str(row.hd) and 'i' in str(row.ad):\n            if row.season!=2023:\n                m=1\n            else:\n                ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\n        else:\n            \n            ga.append([ht,at,row.neutral,row.season,row.date,row.homep,row.awayp,'vs'])\n    \n    \n    \nfrom2000=pd.DataFrame(ga)\nfrom2000.columns=['home','away','neutral','season','date','homep','awayp','venue1']\nfor season in from2000.season.unique():\n    tds[season]={ }\nfor row in from2000.itertuples():\n    tds[row.season][row.home]='yes'\n    tds[row.season][row.away]='yes'\ndoms=1\ndc=1\nconfm=1\neloLeaguez.addPlayer(\"St John's (NY)\")\neloLeaguez.addPlayer(\"Fairfield\")\nfrom2000=from2000.astype(\"string\")\nfrom2000=from2000.astype({\"homep\":float,'awayp':float,'season':float})\nfrom2000['venue1']=from2000['venue1'].replace(\"-1\",\"@\")\nfrom2000=from2000.replace(\"S Carolina St\",\"South Carolina State\")\nfrom2000['venue1']=from2000['venue1'].replace(\"1\",\"vs\")\nteams=set(njcaa.home.tolist()+njcaa.away.tolist())\nfrom2000=from2000.drop_duplicates()\nfrom2000['date']=from2000.date.str.replace(\"'\",\"\")\nfrom2000.sort_values(by='date',inplace=True)\nfrom20000=from2000\nfrom2000=from2000[from2000.date<str(today)]\nfrom2000=from2000[from2000.homep.notna()]\nfrom2000=from2000[from2000.awayp.notna()]\nr = requests.get('https://ontheroadtovote.com/ncaaf/fbsteams.json')\ny=r.json()\nnaiadf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/naiastandings1969-1994.csv\")\n\nfor team in y:\n    from2000=from2000.replace(team,y[team])\nr = requests.get('https://ontheroadtovote.com/ncaaf/fcs/teams.json')\ny=r.json()\n\nfor team in y:\n    from2000=from2000.replace(team,y[team])\nteams=set(from2000.home.tolist()+from2000.away.tolist())\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nnaiadf=naiadf.astype({\"Team\":\"string\",\"Wins\":float,\"Losses\":float,\"Season\":float})\nteams=set(naiadf.Team.tolist())\n\nfor team in teams:\n    eloLeaguez.addPlayer(str(team),rating=1500)\nfcss=[]\nfcsvnon=[]\nfrom2000=from2000.drop_duplicates()\nfor game in from2000.itertuples():\n    if game.season>1977:\n        if game.home in str(fbsteams[game.season]) and game.away in str(teamzzz[game.season]):\n            fcss.append(game.awayp-game.homep)\n        if game.away in str(fbsteams[game.season]) and game.home in str(teamzzz[game.season]):\n            fcss.append(game.homep-game.awayp)\n        if game.away not in str(fbsteams[game.season]) and game.away not in str(teamzzz[game.season]) and game.home in str(teamzzz[game.season]):\n            fcsvnon.append(game.homep-game.awayp)\n        if game.home not in str(fbsteams[game.season]) and game.home not in str(teamzzz[game.season]) and game.away in str(teamzzz[game.season]):\n            fcsvnon.append(game.awayp-game.homep)\nnaiateams={}\nfor i in range(1969,1995):\n    naiateams[float(i)]={}\n\nfor row in naiadf.itertuples():\n    naiateams[row.Season][row.Team]={}\n    naiateams[row.Season][row.Team]['W']=float(row.Wins)\n    naiateams[row.Season][row.Team]['L']=float(row.Losses)\n    \n    \nfor game in from2000.itertuples():\n    fcs=abs(round(np.mean(fcss))*20)*2\n    fcsv=abs(round(np.mean(fcsvnon))*20)*2\n    hpen=0\n    apen=0\n    if game.season>1977:\n        if game.away not in str(fbsteams[game.season]) and game.away not in str(teamzzz[game.season]) and game.home in str(teamzzz[game.season]):\n            apen=fcsv\n        if game.home not in str(fbsteams[game.season]) and game.home not in str(teamzzz[game.season]) and game.away in str(teamzzz[game.season]):\n            hpen=fcsv\n        if game.home in str(fbsteams[game.season]) and game.away in str(teamzzz[game.season]):\n            apen=fcs\n        if game.away in str(fbsteams[game.season]) and game.home in str(teamzzz[game.season]):\n            hpen=fcs\n    season=game.season\n    if (season >currSeason):\n        if season>1968 and season<1995:\n            previousnaia=naiadf[naiadf.Season<game.season]\n            for team in naiateams[game.season]:\n                if team not in ct:\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    eloLeaguez.ratingDict[team]+=naiateams[game.season][team]['W']\n                    eloLeaguez.ratingDict[team]-=naiateams[game.season][team]['L']\n        lsdf=from2000[from2000.season<game.season]\n        ls=set(lsdf.home.tolist()+lsdf.away.tolist())\n        ctdf=from2000[from2000.season==game.season]\n        ct=set(ctdf.home.tolist()+ctdf.away.tolist())\n        \n        for key in ls:\n            if key in ct:\n                if game.season<1978:\n                    eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1500) * (1/3.))\n                if game.season>1977:\n                    if key in str(fbsteams[game.season]):\n                        \n                        eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1500) * (1/3.))\n                    if key in str(teamzzz[game.season]):\n                        eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n                    if key not in str(teamzzz[game.season]) and key not in str(fbsteams[game.season]):\n                        eloLeaguez.ratingDict[key]=eloLeaguez.ratingDict[key] - ((eloLeaguez.ratingDict[key] - 1200) * (1/3.))\n\n        currSeason=game.season\n    if 'vs' in str(game.venue1):\n        \n        ht=game.home\n        at=game.away\n        hp=game.homep\n        ap=game.awayp\n    else:\n        at=game.home\n        ht=game.away\n        ap=game.homep\n        hp=game.awayp\n    if (hp > ap)or(hp==ap):\n        \n        \n    \n        eloLeaguez.gameOver(ht,at,True,game.neutral,hp,ap,hpen,apen)\n    \n    \n    if ap>hp:\n        \n        eloLeaguez.gameOver(at, ht,False,game.neutral,ap,hp,apen,hpen)\nprint(\"{\")\na=0\ntp=0\nfor team in eloLeaguez.ratingDict.keys():\n  if tp==1:\n      my=[]\n      print(team,\":\",eloLeaguez.ratingDict[team])\ntxtz='\"','Team','\"',':','20'\nprint('\"','Team','\"',':','20')\nprint(\"}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T21:22:52.445353Z","iopub.execute_input":"2023-12-28T21:22:52.445933Z","iopub.status.idle":"2023-12-28T21:36:39.028430Z","shell.execute_reply.started":"2023-12-28T21:22:52.445891Z","shell.execute_reply":"2023-12-28T21:36:39.026532Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2023\n2023\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\ndidfcs\nready\n{\n\" Team \" : 20\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"teams[1969]","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:29:15.611003Z","iopub.execute_input":"2023-12-28T22:29:15.611602Z","iopub.status.idle":"2023-12-28T22:29:15.621775Z","shell.execute_reply.started":"2023-12-28T22:29:15.611543Z","shell.execute_reply":"2023-12-28T22:29:15.620421Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"['Henderson State',\n 'Arkansas Tech',\n 'Harding',\n 'State College of Arkansas',\n 'Ouachita Baptist',\n 'Southern Arkansas',\n 'Arkansas A&M']"},"metadata":{}}]},{"cell_type":"code","source":"naiadf","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:26:42.811352Z","iopub.execute_input":"2023-12-28T22:26:42.811819Z","iopub.status.idle":"2023-12-28T22:26:42.830025Z","shell.execute_reply.started":"2023-12-28T22:26:42.811780Z","shell.execute_reply":"2023-12-28T22:26:42.828511Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                    Team Wins Losses  Season\n0        Henderson State    8      2    1969\n1          Arkansas Tech    6      4    1969\n2                Harding    7      2    1969\n3         Arkansas State    5      5    1969\n4       Ouachita Baptist    5      5    1969\n..                   ...  ...    ...     ...\n432        Arkansas Tech    7      4    1994\n433              Harding    5      4    1994\n434  Arkansas-Monticello    4      4    1994\n435     Ouachita Baptist    5      5    1994\n436    Southern Arkansas    1      7    1994\n\n[437 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Team</th>\n      <th>Wins</th>\n      <th>Losses</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Henderson State</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1969</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Arkansas Tech</td>\n      <td>6</td>\n      <td>4</td>\n      <td>1969</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Harding</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1969</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas State</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1969</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ouachita Baptist</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1969</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>Arkansas Tech</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>Harding</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>Arkansas-Monticello</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>Ouachita Baptist</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>Southern Arkansas</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1994</td>\n    </tr>\n  </tbody>\n</table>\n<p>437 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom bs4 import BeautifulSoup\nimport requests\nteams={}\narr=[]\nfor i in range(1969,1995):\n    teams[i]=[]\nfor i in range(1969,1995):\n    url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NAIA_Division_II_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    my_table=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    index=0     \n    for table in my_table:\n        for j in table.find_all(\"tr\")[1:]:\n            statements=\"Team\" not in str(j) and 'title' not in str(j) and 'legend' not in str(j)\n        \n        \n        \n                    \n            if  'Team' not in str(j) and 'conference' not in str(j) and \"style\" not in str(j) and 'Division' not in str(j) and 'League' not in str(j) and 'legend' not in str(j) and 'header' not in str(j):\n            \n            \n            \n                row_data = j.find_all(\"td\")\n                team=row_data[0].text\n                team=team.replace(\"$\",\"\")\n                team=team.replace(\"\\n\",\"\")\n                team=team.replace(\"xy\",\"\")\n                team=team.replace(\" x\",\"\")\n                team=team.replace(\" y\",\"\")\n                team=team.replace(\"^\",\"\")\n                team=team.replace(\"+\",\"\")\n                team=re.sub(r'^.*?1', '', team)\n                team=re.sub(r'^.*?2', '', team)\n                team=re.sub(r'^.*?3', '', team)\n                team=team.replace(\"*\",\"\")\n                team=team.replace(\"1\",\"\")\n                team=team.replace(\"2\",\"\")\n                team=re.sub(r'^.*?4', '', team)\n                team=re.sub(r'^.*?5', '', team)\n                team=re.sub(r'^.*?6', '', team)\n                team=re.sub(r'^.*?7', '', team)\n                team=re.sub(r'^.*?8', '', team)\n                team=re.sub(r'^.*?9', '', team)\n                team=re.sub(r'^.*?0', '', team)\n                team=team.rstrip()\n                wins=row_data[8].text\n                wins=wins.replace(\"\\n\",\"\")\n                losses=row_data[10].text\n                losses=losses.replace(\"\\n\",\"\")\n                team=team.strip()\n                row = [team,wins,losses,i]\n                arr.append(row)\n                if team not in str(teams):\n                \n                    teams[i].append(team)\nfor i in range(1969,1995):\n    url=\"https://en.wikipedia.org/wiki/\"+str(i)+\"_NAIA_Division_I_football_season\"\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    my_table=soup.find_all(\"table\",{\"class\":\"standings-box\"})\n    index=0 \n    for table in my_table:\n        \n        \n        for j in table.find_all(\"tr\")[1:]:\n            statements=\"Team\" not in str(j) and 'title' not in str(j) and 'legend' not in str(j)\n        \n        \n        \n                    \n            if  'Team' not in str(j) and 'conference' not in str(j) and \"style\" not in str(j) and 'legend' not in str(j) and 'header' not in str(j):\n            \n            \n            \n                row_data = j.find_all(\"td\")\n                team=row_data[0].text\n                team=team.replace(\"$\",\"\")\n                team=team.replace(\"\\n\",\"\")\n                team=team.replace(\"xy\",\"\")\n                team=team.replace(\" x\",\"\")\n                team=team.replace(\" y\",\"\")\n                team=team.replace(\"^\",\"\")\n                team=team.replace(\"*\",\"\")\n                team=team.replace(\"+\",\"\")\n                team=re.sub(r'^.*?1', '', team)\n                team=re.sub(r'^.*?2', '', team)\n                team=re.sub(r'^.*?3', '', team)\n                team=re.sub(r'^.*?4', '', team)\n                team=re.sub(r'^.*?5', '', team)\n                team=re.sub(r'^.*?6', '', team)\n                team=re.sub(r'^.*?7', '', team)\n                team=re.sub(r'^.*?8', '', team)\n                team=re.sub(r'^.*?9', '', team)\n                team=re.sub(r'^.*?0', '', team)\n        \n                team=team.replace(\"1\",\"\")\n                team=team.replace(\"2\",\"\")\n                team=team.rstrip()\n                wins=row_data[8].text\n                wins=wins.replace(\"\\n\",\"\")\n                losses=row_data[10].text\n                losses=losses.replace(\"\\n\",\"\")\n                team=team.strip()\n                row = [team,wins,losses,i]\n                arr.append(row)\n                if team not in str(teams):\n                \n                    teams[i].append(team)\n            \n            \n                    \n                    \n            \n\nnaiad1=teams\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:42:52.752194Z","iopub.execute_input":"2023-12-28T22:42:52.752752Z","iopub.status.idle":"2023-12-28T22:43:25.295459Z","shell.execute_reply.started":"2023-12-28T22:42:52.752704Z","shell.execute_reply":"2023-12-28T22:43:25.294117Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"row_data","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:42:31.985266Z","iopub.execute_input":"2023-12-28T22:42:31.985792Z","iopub.status.idle":"2023-12-28T22:42:31.994577Z","shell.execute_reply.started":"2023-12-28T22:42:31.985753Z","shell.execute_reply":"2023-12-28T22:42:31.993127Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"[<td class=\"header\" colspan=\"99\">Northern\n </td>]"},"metadata":{}}]},{"cell_type":"code","source":"\nnaiadf=pd.DataFrame(arr,columns=['Team','Wins','Losses',\"Season\"])\ny=requests.get(\"https://ontheroadtovote.com/ncaaf/fcs/naiateams.json\")\ny=y.json()\nfor team in y:\n    naiadf=naiadf.replace(team,y[team])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:44:47.056669Z","iopub.execute_input":"2023-12-28T22:44:47.057109Z","iopub.status.idle":"2023-12-28T22:44:47.572497Z","shell.execute_reply.started":"2023-12-28T22:44:47.057074Z","shell.execute_reply":"2023-12-28T22:44:47.571223Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"for team in set(naiadf.Team.tolist()):\n    if team not in eloLeaguez.ratingDict.keys():\n        print(team)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:22:51.916846Z","iopub.execute_input":"2023-12-28T22:22:51.918252Z","iopub.status.idle":"2023-12-28T22:22:51.927078Z","shell.execute_reply.started":"2023-12-28T22:22:51.918189Z","shell.execute_reply":"2023-12-28T22:22:51.925590Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Oregon Tech\n","output_type":"stream"}]},{"cell_type":"code","source":"naiadf.to_csv(\"naia1969-1994.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:24:08.192362Z","iopub.execute_input":"2023-12-28T22:24:08.192870Z","iopub.status.idle":"2023-12-28T22:24:08.204561Z","shell.execute_reply.started":"2023-12-28T22:24:08.192829Z","shell.execute_reply":"2023-12-28T22:24:08.202868Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"naiadf.to_csv(\"naiastandings1969-1994.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:45:37.338323Z","iopub.execute_input":"2023-12-28T22:45:37.338848Z","iopub.status.idle":"2023-12-28T22:45:37.370243Z","shell.execute_reply.started":"2023-12-28T22:45:37.338812Z","shell.execute_reply":"2023-12-28T22:45:37.368486Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"j=1\nfor i in range(1978,2024):\n    u=[]\n    for key in teamzzz[i]:\n        \n        if key not in eloLeaguez.ratingDict.keys():\n            if 'standings' not in str(key) and \"Poll\" not in str(key) and 'football' not in str(key):\n                \n                key=key.replace(\"  \",\"\")\n                u.append(key)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.120381Z","iopub.status.idle":"2023-12-27T16:16:17.120773Z","shell.execute_reply.started":"2023-12-27T16:16:17.120579Z","shell.execute_reply":"2023-12-27T16:16:17.120598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"currentweek=from20000[from20000['date'].str.contains('2024-01-07')]\nfor row in currentweek.itertuples():\n    hpen=0\n    game=row\n    apen=0\n    if game.away not in str(fbsteams[game.season]) and game.away not in str(teamzzz[game.season]) and game.home in str(teamzzz[game.season]):\n        apen=fcsv\n    if game.home not in str(fbsteams[game.season]) and game.home not in str(teamzzz[game.season]) and game.away in str(teamzzz[game.season]):\n        hpen=fcsv\n    if row.home in str(fbsteams[row.season]) and row.away in str(teamzzz[row.season]):\n        apen=fcs\n    if row.away in str(fbsteams[row.season]) and row.home in str(teamzzz[row.season]):\n        hpen=fcs\n    if row.neutral==True:\n        helo=eloLeaguez.ratingDict[row.home]-hpen\n    else:\n        helo=eloLeaguez.ratingDict[row.home]+100-hpen\n    aelo=eloLeaguez.ratingDict[row.away]-apen\n    \n    if aelo>helo:\n        \n        spread=aelo-helo\n        spread=spread/20\n        spread=round(spread)\n        if spread==0:\n            spread=1\n        print(row.away+\" \"+\"beats \"+\" \"+row.home+\" \"+ \"by \"+str(spread)+\" <br/>\")\n    if helo>aelo or helo==aelo:\n        spread=helo-aelo\n        spread=spread/20\n        spread=round(spread)\n        if spread==0:\n            spread=1\n        print(row.home+\" \"+\"beats \"+\" \"+row.away+\" \"+ \"by \"+str(spread)+\" <br/>\")\n    \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-28T18:40:37.713495Z","iopub.execute_input":"2023-12-28T18:40:37.713925Z","iopub.status.idle":"2023-12-28T18:40:38.482917Z","shell.execute_reply.started":"2023-12-28T18:40:37.713891Z","shell.execute_reply":"2023-12-28T18:40:38.481755Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"South Dakota State beats  Montana by 13 <br/>\n","output_type":"stream"}]},{"cell_type":"code","source":"tp=0\nn={}\nn['f']=0\nn['t']=0\nfor row in fcs.itertuples():\n    tp+=(row.homep+row.awayp)\n    if 'True' in str(row.neutral):\n        n['t']+=1\n    else:\n        n['f']+=1\n    \ntp","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.137352Z","iopub.status.idle":"2023-12-27T16:16:17.138095Z","shell.execute_reply.started":"2023-12-27T16:16:17.137844Z","shell.execute_reply":"2023-12-27T16:16:17.137873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/fcs/d31995-2022.csv\")\ndf1['Schl']=df1['Schl'].str.replace(\"_\",\" \")\ndf1['Opp']=df1['Opp'].str.replace(\"_\",\" \")\n    \nh=[]\nfor team in set(df1.Schl.tolist()+df1.Opp.tolist()):\n    if team not in eloLeaguez.ratingDict.keys():\n        print(team)\n        h.append(team)\nprint(len(h))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T16:16:17.143911Z","iopub.status.idle":"2023-12-27T16:16:17.144327Z","shell.execute_reply.started":"2023-12-27T16:16:17.144128Z","shell.execute_reply":"2023-12-27T16:16:17.144148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=input(\"school\")\nfor key in eloLeaguez.ratingDict.keys():\n    if s in key:\n        print(key)\nosz=input(\"String to replace\")\na[osz]=0\nrs=input(\"Replace with\")\na[osz]=str(rs)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T20:55:00.708739Z","iopub.execute_input":"2023-12-27T20:55:00.709197Z","iopub.status.idle":"2023-12-27T20:55:51.918356Z","shell.execute_reply.started":"2023-12-27T20:55:00.709162Z","shell.execute_reply":"2023-12-27T20:55:51.917231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1=input(\"t1\")\nt2=input(\"t2\")\n\nf=input(\"fcs\")\nh=200\nif str(1) in f:\n    ap=200\nelse:\n    ap=0\nt1e=eloLeaguez.ratingDict[t1]+h\nt2e=eloLeaguez.ratingDict[t2]-ap\nprint(t1+\" by \"+str((t1e-t2e)/20))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T18:43:55.612884Z","iopub.execute_input":"2023-12-28T18:43:55.614837Z","iopub.status.idle":"2023-12-28T18:44:05.784922Z","shell.execute_reply.started":"2023-12-28T18:43:55.614777Z","shell.execute_reply":"2023-12-28T18:44:05.783273Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdin","text":"t1 Tennessee State\nt2 Mississippi Valley State\nfcs 0\n"},{"name":"stdout","text":"Tennessee State by 21.991339181111336\n","output_type":"stream"}]},{"cell_type":"code","source":"n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:58:37.618761Z","iopub.execute_input":"2023-12-27T19:58:37.619184Z","iopub.status.idle":"2023-12-27T19:58:37.626346Z","shell.execute_reply.started":"2023-12-27T19:58:37.619149Z","shell.execute_reply":"2023-12-27T19:58:37.625236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2023-12-27T23:51:42.663206Z","iopub.execute_input":"2023-12-27T23:51:42.663618Z","iopub.status.idle":"2023-12-27T23:51:42.685711Z","shell.execute_reply.started":"2023-12-27T23:51:42.663583Z","shell.execute_reply":"2023-12-27T23:51:42.684427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gz=[]\nnjcaaurlss={\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12814&all=1&mode=3&format=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12814&all=1&mode=3&format=1\",\"2000\":\"https://masseyratings.com/scores.php?s=41845&sub=12814&all=1&mode=3&format=1\",\"2001\":\"https://masseyratings.com/scores.php?s=41846&sub=12814&all=1&mode=3&format=1\",\"2002\":\"https://masseyratings.com/scores.php?s=41847&sub=12814&all=1&mode=3&format=1\",\"2003\":\"https://masseyratings.com/scores.php?s=41848&sub=12814&all=1&mode=3&format=1\",\"2004\":\"https://masseyratings.com/scores.php?s=41849&sub=12814&all=1&mode=3&format=1\",\"2005\":\"https://masseyratings.com/scores.php?s=41850&sub=12814&all=1&mode=3&format=1\",\"2006\":\"https://masseyratings.com/scores.php?s=68033&sub=12814&all=1&mode=3&format=1\",\"2007\":\"https://masseyratings.com/scores.php?s=73929&sub=12814&all=1&mode=3&format=1\",\"2008\":\"https://masseyratings.com/scores.php?s=85513&sub=12814&all=1&mode=3&format=1\",\"2009\":\"https://masseyratings.com/scores.php?s=94988&sub=12814&all=1&mode=3&format=1\",\"2010\":\"https://masseyratings.com/scores.php?s=98700&sub=12814&all=1&mode=3&format=1\",\"2011\":\"https://masseyratings.com/scores.php?s=107811&sub=12814&all=1&mode=3&format=1\",\"2012\":\"https://masseyratings.com/scores.php?s=181623&sub=12814&all=1&mode=3&format=1\",\"2014\":\"https://masseyratings.com/scores.php?s=262657&sub=12814&all=1&mode=3&format=1\",\"2015\":\"https://masseyratings.com/scores.php?s=279541&sub=12814&all=1&mode=3&format=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12814&all=1&mode=3&format=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12814&all=1&mode=3&format=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12814&all=1&mode=3&format=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12814&all=1&mode=3&format=1\",\"2020\":\"https://masseyratings.com/scores.php?s=318889&sub=12814&all=1&mode=3&format=1\"}\nnjcaaurls={\"2023\":\"https://masseyratings.com/scores.php?s=539277&sub=12799&all=1&mode=3&format=1\",\"2016\":\"https://masseyratings.com/scores.php?s=286577&sub=12799&all=1&mode=3&format=1\",\"2017\":\"https://masseyratings.com/scores.php?s=295489&sub=12799&all=1&mode=3&format=1\",\"2018\":\"https://masseyratings.com/scores.php?s=300937&sub=12799&all=1&mode=3&format=1\",\"2019\":\"https://masseyratings.com/scores.php?s=308075&sub=12799&all=1&mode=3&format=1\",\"2021\":\"https://masseyratings.com/scores.php?s=358435&sub=12799&all=1&mode=3&format=1\",\"2022\":\"https://masseyratings.com/scores.php?s=384031&sub=12799&all=1&mode=3&format=1\"}\nfor key in njcaaurls:\n    gg=[]\n    r = requests.get(njcaaurls[key])\n    soup = bs(r.content, 'lxml')\n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(bs(r.content, 'lxml'))\n    q=aa\n    q=q.split(\"\\n\")\n    for line in q:\n        \n        \n        \n        \n        line=str(line)\n        \n        \n        \n        line = list(line.split(', '))\n        if \"<\" not in str(line):\n            \n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(key)]\n            gg.append(row)\n        if \"<p>\" in str(line):\n            line=str(line)\n            line=line.split(\"<p>\")\n            line=line[1]\n            line=list(line.split(', '))\n            date=str(line[0])\n            datey=date.split(\",\")\n            date=datey[1]\n            row=[datey[1],line[1],line[2],line[3],line[4],line[5],line[6],float(key)]\n            gg.append(row)\n    d22=pd.DataFrame(gg,columns=['Date','Schl','venue1','PTS','Opp','venue2','OPP','Year'])\n    \n    nof=njcaaurls[key]\n    nof=str(nof)\n    nof=nof.split(\"&format=\")\n    nof=nof[0]\n    nof=nof+\"&format=2\"\n    htmlz=requests.get(nof).text\n    soupz=BeautifulSoup(htmlz)\n    tds={}\n    d22.reset_index(inplace=True)\n    d22 = d22.astype({\"Schl\": str, \"Opp\": str})\n    d22=d22.astype(\"string\")\n    d22['Schl']=d22['Schl'].str.replace(\"'\",\"\")\n    d22['Opp']=d22['Opp'].str.replace(\"'\",\"\")\n    d22['PTS']=d22['PTS'].str.replace(\"'\",\"\")\n    d22['OPP']=d22['OPP'].str.replace(\"'\",\"\")\n    d22['venue1']=d22['venue1'].str.replace(\"'\",\"\")\n    d22['venue2']=d22['venue2'].str.replace(\"'\",\"\")\n    for line in soupz.text.split('\\n')[:-1]:\n        k=str(line)\n        k=k.replace(\" \",\"\")\n        k=k.split(\",\")\n  \n        tds[float(k[0])]=k[1]\n    for row in d22.itertuples():\n        schl=str(row.Schl)\n        schl=schl.replace(\" \",\"\")\n        schl=float(schl)\n        d22.at[row.Index,\"Schl\"]=tds[schl]\n        o=str(row.Opp)\n        o=o.replace(\" \",\"\")\n        o=float(o)\n        d22.at[row.Index,\"Opp\"]=tds[o]\n    for row in d22.itertuples():\n        ap=str(row.OPP)\n        ap=ap.replace(\"]\",\"\")\n        gz.append([row.Date,row.Schl,row.venue1,row.PTS,row.Opp,row.venue2,float(ap),row.Year])\n    print(key)\nd22=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd22=pd.DataFrame(gz,columns=['Date', 'Schl', 'venue1', 'PTS', 'Opp', 'venue2', 'OPP',\n       'Year'])\nd22.reset_index(inplace=True)\nd22=d22.astype('string')\n\nd22['venue1']=d22['venue1'].replace(\" 0\",\"vs\")\nd22['venue2']=d22['venue2'].replace(\" 0\",\"True\")\nd22['venue1']=d22['venue1'].replace(\" 1\",\"vs\")\nd22['venue1']=d22['venue1'].replace(\"-1\",\"@\")\nd22=d22.rename(columns={'venue2':'neutral','venue1':'Venue'})\nd22=d22.rename(columns={'Schl':'home','Opp':'away','PTS':'homep','OPP':'awayp','Year':'season',\"Date\":'date','Venue':'venue1'})\nd22['neutral']=d22['neutral'].str.replace(\"-1\",'False')\nd22['neutral']=d22['neutral'].str.replace(\"1\",'False')\nd22['neutral']=d22['neutral'].str.replace(\"0\",'True')","metadata":{"execution":{"iopub.status.busy":"2023-12-28T00:25:21.915533Z","iopub.execute_input":"2023-12-28T00:25:21.915990Z","iopub.status.idle":"2023-12-28T00:25:30.705790Z","shell.execute_reply.started":"2023-12-28T00:25:21.915952Z","shell.execute_reply":"2023-12-28T00:25:30.704350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=input(\"school\")\nfor key in eloLeaguez.ratingDict.keys():\n    if s in key:\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T22:20:01.765089Z","iopub.execute_input":"2023-12-28T22:20:01.766542Z","iopub.status.idle":"2023-12-28T22:20:04.208053Z","shell.execute_reply.started":"2023-12-28T22:20:01.766493Z","shell.execute_reply":"2023-12-28T22:20:04.206496Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdin","text":"school Wheaton\n"},{"name":"stdout","text":"Wheaton High\nWheaton IL\n","output_type":"stream"}]},{"cell_type":"code","source":"for key in set(d22.home.tolist()+d22.away.tolist()):\n    if key not in eloLeaguez.ratingDict.keys():\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:34:40.443944Z","iopub.execute_input":"2023-12-28T13:34:40.445187Z","iopub.status.idle":"2023-12-28T13:34:40.453337Z","shell.execute_reply.started":"2023-12-28T13:34:40.445142Z","shell.execute_reply":"2023-12-28T13:34:40.452049Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Keiser\nMadonna\nWebber\nWayland\n","output_type":"stream"}]}]}